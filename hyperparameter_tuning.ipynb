{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import utils, training, constants\n",
    " \n",
    "dataset = utils.data_loader(constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [10],  \n",
    "              'gamma': [0.0359,0.0361,0.0363,0.0365,0.0367,0.0369,0.0371], \n",
    "              'kernel': ['rbf'],\n",
    "              'degree': [3]}  \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "print('Result of the best model on the test set: ', grid_predictions)\n",
    "print(grid.best_params_) \n",
    "\n",
    "archive = '''\n",
    "besto_model = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "model = besto_model\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "test_acc\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import utils, training, constants\n",
    "\n",
    "dataset = utils.data_loader(constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'n_neighbors': list(range(89,90)),\n",
    "              'weights':['uniform','distance'],\n",
    "              'algorithm':['ball_tree','kd_tree','brute','auto'],\n",
    "              'p':list(range(1,3)),\n",
    "              'metric':['cityblock','cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']}  \n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "print('Result of the best model on the test set: ', grid_predictions)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'brute', 'metric': 'cosine', 'n_neighbors': 89, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657601977750309"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "besto_model = KNeighborsClassifier(algorithm = 'brute',metric='cosine',weights='distance', n_neighbors= 89, p= 1)\n",
    "model = besto_model\n",
    "dataset = utils.data_loader(csv_file)\n",
    "reduced_dataset = utils.channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import utils, training, constants\n",
    " \n",
    "dataset = utils.data_loader(constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "  \n",
    "# defining parameter range \n",
    "depths = list(range(1, 100))\n",
    "param_grid = {'max_depth': depths}  \n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import utils, training, constants\n",
    " \n",
    "dataset = utils.data_loader(constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "  \n",
    "# defining parameter range \n",
    "a='''param_grid = {'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150]}'''\n",
    "\n",
    "param_grid = {'learning_rate': [1.0],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150]}\n",
    "              \n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the best model on the test set:  0.9237818181818181\n",
      "{'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the best model on the test set:  0.8603213844252163\n",
      "{'learning_rate': 1.0, 'max_depth': 12, 'n_estimators': 80}\n",
      "Result of the best model on the test set:  0.8331273176761433\n"
     ]
    }
   ],
   "source": [
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)\n",
    "model = GradientBoostingClassifier(learning_rate= 0.01,  max_depth= 12, n_estimators= 500)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = model.predict(X_test)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from selection import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature dataset as a dataframe\n",
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "\n",
    "#channel subsets\n",
    "test_channels_1 = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "test_channels_2 =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "test_channels_3 = [\"Cz\",\"CP3\",\"CPz\",\"P3\",\"FT7\",\"FC3\",\"FCZ\",\"FC4\",\"C4\",\"CP4\",\"TP8\",\"T5\",\"PZ\",\"T6\",\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "csv_file = 'eeg_features.csv'\n",
    "\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset_all = channel_selection(dataset, channel_names)\n",
    "reduced_dataset_1 = channel_selection(dataset, test_channels_1)\n",
    "reduced_dataset_1 = channel_selection(dataset, test_channels_1)\n",
    "reduced_dataset_2 = channel_selection(dataset, test_channels_2)\n",
    "reduced_dataset_3 = channel_selection(dataset, test_channels_3)\n",
    "\n",
    "all_features = reduced_dataset_all.columns[:len(reduced_dataset_all.columns) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Channel Training+Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = incremental_training(dataset=dataset, channel_list=channel_list, feature_subset=all_features, models=['K-NN'], mode='feature', save=True)\n",
    "#calculate accuracy for each channel\n",
    "for channel in channel_names:\n",
    "    print(channel)\n",
    "    models = ['K-NN', 'GBC']\n",
    "    dataset = data_loader(csv_file)\n",
    "    reduced_dataset = channel_selection(dataset, [channel])\n",
    "    data = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "    for model in models:\n",
    "        model_training(data, model, stats=False, cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['time_features'] = ['skew', 'kurtosis', 'rms', 'activity', 'mobility', 'complexity', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['freq_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
    "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2',\n",
    "               'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10',\n",
    "               'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['chr_features'] = ['chr_0',\n",
    "                'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8',\n",
    "                'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15',\n",
    "                'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "feature_subsets['coeffs'] = feature_subsets['spectral_features'] + feature_subsets['music']\n",
    "\n",
    "feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "feature_subsets['no_music'] = feature_subsets['spectral_features'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "[9.61122204e-04 1.32769601e-02 4.52022765e-05 1.14850126e-04\n",
      " 1.46696411e-01 3.41439638e-02 5.50141926e-04 1.73017930e-01\n",
      " 1.27794911e-05 5.95554735e-01 1.64004219e-02 2.45363941e-03\n",
      " 1.74598074e-03 1.90097009e-03 4.07508321e-04 4.09518615e-05\n",
      " 1.38604829e-07 6.40116156e-08 1.08295123e-07 5.95035833e-07\n",
      " 4.29405958e-09 1.21101518e-07 2.73710907e-07 3.06856177e-06\n",
      " 1.28039626e-07 6.14554923e-01 9.91577860e-01 8.18741805e-07\n",
      " 1.69715298e-02 3.69053002e-05 2.73610859e-22 1.96272622e-02\n",
      " 4.60854320e-03 1.00392340e-08 1.65991722e-11 7.90110477e-03\n",
      " 6.13653500e-01 3.17908865e-03 3.34516977e-08 4.17076510e-15\n",
      " 1.48348661e-01 3.43969065e-01 1.07368849e-08 2.01180145e-06\n",
      " 2.53879490e-03 1.45938320e-02 1.44444470e-06 3.65287390e-02\n",
      " 9.40519911e-01 8.65323072e-04 7.06627439e-06 8.42153573e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset_1, feature_subset=feature_subsets['no_music'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "chi2_stats, p_values = chi2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['no_music']):\n",
    "    chi2_dict[feature] = chi2_stats[idx]\n",
    "dict(sorted(chi2_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_df, variance_dict = variance_thresholding(reduced_dataset_1, threshold=0.2)\n",
    "print(variance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset_1, feature_subset=feature_subsets['no_music'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "f_statistic, p_values = f_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spc_roff': 1179.7978846086457,\n",
       " 'complexity': 1171.7471438323246,\n",
       " 'mel_11': 1160.4100113966963,\n",
       " 'mel_10': 1144.9544212153526,\n",
       " 'mel_6': 1075.6277307751693,\n",
       " 'mel_7': 952.5670299279793,\n",
       " 'mel_12': 942.540337366972,\n",
       " 'mel_9': 936.5967676403434,\n",
       " 'mel_8': 891.0888782245993,\n",
       " 'mel_14': 820.7423233308908,\n",
       " 'mel_13': 764.8618977509211,\n",
       " 'rms': 724.8313528466728,\n",
       " 'spc_cnt': 717.5656346396459,\n",
       " 'mel_5': 707.6203337209621,\n",
       " 'alpha_power': 674.0351116859397,\n",
       " 'theta_power': 659.5643477476898,\n",
       " 'mfcc_8': 541.380384782955,\n",
       " 'mfcc_2': 457.90180619717114,\n",
       " 'gamma_beta': 427.4471517208908,\n",
       " 'mel_4': 384.0438940190917,\n",
       " 'mfcc_3': 360.71091534674434,\n",
       " 'mel_3': 349.0845613165568,\n",
       " 'mobility': 347.5485006669642,\n",
       " 'mfcc_0': 332.5889617865878,\n",
       " 'mfcc_6': 326.9010075256861,\n",
       " 'mel_2': 303.7056483738949,\n",
       " 'mel_1': 281.4245060104526,\n",
       " 'zc': 265.22149867835975,\n",
       " 'mean_abs_sec_dif': 256.20641049970425,\n",
       " 'beta_alpha': 249.93641970469574,\n",
       " 'dfa': 247.85245951014025,\n",
       " 'alpha_delta': 223.3189549940299,\n",
       " 'mfcc_1': 222.73801619514452,\n",
       " 'gamma_alpha': 221.68789062284478,\n",
       " 'mel_0': 206.97428757132352,\n",
       " 'delta_power': 189.24747385962695,\n",
       " 'alpha_theta': 140.99860515145866,\n",
       " 'gamma_theta': 139.227799134458,\n",
       " 'activity': 124.01221602503415,\n",
       " 'mfcc_5': 114.55056121277767,\n",
       " 'gamma_delta': 87.2479717194567,\n",
       " 'mfcc_4': 85.58181451221179,\n",
       " 'beta_theta': 76.57521864315568,\n",
       " 'slope': 70.94363200155608,\n",
       " 'skew': 61.96560616320828,\n",
       " 'beta_power': 58.20123475753122,\n",
       " 'theta_delta': 56.425180697711724,\n",
       " 'mfcc_7': 51.31978952080081,\n",
       " 'mfcc_9': 13.583291383945342,\n",
       " 'gamma_power': 9.381093678486982,\n",
       " 'beta_delta': 0.06262726708045808,\n",
       " 'kurtosis': 0.003441500200284913}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['no_music']):\n",
    "    f_dict[feature] = f_statistic[idx]\n",
    "dict(sorted(f_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Value Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n"
     ]
    }
   ],
   "source": [
    "channel_subsets = [channel_names, test_channels_1, test_channels_2, test_channels_3]\n",
    "subset_names = ['chn_all', 'chn_1', 'chn_2', 'chn_3']\n",
    "p_val_df = pd.DataFrame(columns=subset_names)\n",
    "\n",
    "for i in range(len(channel_subsets)):\n",
    "    dataset = data_loader(csv_file)\n",
    "    reduced_dataset_i = channel_selection(dataset, channel_subsets[i])\n",
    "    p_i, p_i_val = p_value_thresholding(reduced_dataset_i, feature_subset=all_features)\n",
    "    p_val_df[subset_names[i]] = p_i_val    \n",
    "\n",
    "p_val_df.to_csv('outs/p_values_by_channels.csv')\n",
    "\n",
    "a='''\n",
    "p_all, p_all_val = p_value_thresholding(reduced_dataset_all, feature_subset=all_features)\n",
    "    p_1, p_1_val = p_value_thresholding(reduced_dataset_1, feature_subset=all_features)\n",
    "    p_2, p_2_val = p_value_thresholding(reduced_dataset_2, feature_subset=all_features)\n",
    "    p_3, p_3_val = p_value_thresholding(reduced_dataset_3, feature_subset=all_features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.79962894\n",
      "Accuracy of K-NN classifier on test set: 0.66913580\n"
     ]
    }
   ],
   "source": [
    "#models = ['K-NN', 'GBC']\n",
    "models = ['K-NN']\n",
    "subset_1 = all_features\n",
    "\n",
    "data = data_preparation(dataset=reduced_dataset, feature_subset=subset_1, pca=True)\n",
    "for model in models:\n",
    "    model_training(data, model, stats=False, cm=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, degree=3, gamma=0.0361, kernel=rbf;, score=0.940 total time=   2.9s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.0359, kernel=rbf;, score=0.940 total time=   3.0s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.0359, kernel=rbf;, score=0.927 total time=   3.1s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.0359, kernel=rbf;, score=0.929 total time=   3.1s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.0361, kernel=rbf;, score=0.920 total time=   3.1s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.0359, kernel=rbf;, score=0.920 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, degree=3, gamma=0.0361, kernel=rbf;, score=0.927 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, degree=3, gamma=0.0359, kernel=rbf;, score=0.934 total time=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=10, degree=3, gamma=0.0361, kernel=rbf;, score=0.934 total time=   3.0s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.0363, kernel=rbf;, score=0.927 total time=   3.1s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.0363, kernel=rbf;, score=0.939 total time=   3.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, degree=3, gamma=0.0363, kernel=rbf;, score=0.929 total time=   3.1s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.0363, kernel=rbf;, score=0.933 total time=   3.0s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.0361, kernel=rbf;, score=0.929 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, degree=3, gamma=0.0363, kernel=rbf;, score=0.920 total time=   3.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=10, degree=3, gamma=0.0365, kernel=rbf;, score=0.939 total time=   3.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, degree=3, gamma=0.0365, kernel=rbf;, score=0.927 total time=   3.4s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.0365, kernel=rbf;, score=0.929 total time=   3.5s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.0365, kernel=rbf;, score=0.920 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, degree=3, gamma=0.0367, kernel=rbf;, score=0.920 total time=   3.6s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.0365, kernel=rbf;, score=0.933 total time=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=10, degree=3, gamma=0.0367, kernel=rbf;, score=0.927 total time=   3.6s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.0367, kernel=rbf;, score=0.939 total time=   4.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, degree=3, gamma=0.0367, kernel=rbf;, score=0.929 total time=   3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=10, degree=3, gamma=0.0369, kernel=rbf;, score=0.920 total time=   3.1s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.0367, kernel=rbf;, score=0.933 total time=   3.3s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.0369, kernel=rbf;, score=0.939 total time=   3.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/opt/homebrew/lib/python3.10/site-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=10, degree=3, gamma=0.0369, kernel=rbf;, score=0.929 total time=   3.2s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.0369, kernel=rbf;, score=0.927 total time=   3.2s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.0369, kernel=rbf;, score=0.933 total time=   3.0s\n",
      "[CV 1/5] END C=10, degree=3, gamma=0.0371, kernel=rbf;, score=0.939 total time=   3.0s\n",
      "[CV 2/5] END C=10, degree=3, gamma=0.0371, kernel=rbf;, score=0.920 total time=   2.8s\n",
      "[CV 3/5] END C=10, degree=3, gamma=0.0371, kernel=rbf;, score=0.927 total time=   2.0s\n",
      "[CV 4/5] END C=10, degree=3, gamma=0.0371, kernel=rbf;, score=0.929 total time=   1.9s\n",
      "[CV 5/5] END C=10, degree=3, gamma=0.0371, kernel=rbf;, score=0.933 total time=   1.9s\n",
      "Result of the best model on the test set:  [1 1 1 ... 0 0 0]\n",
      "{'C': 10, 'degree': 3, 'gamma': 0.0359, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    " \n",
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "  \n",
    "# defining parameter range \n",
    "param_grid = {'C': [10],  \n",
    "              'gamma': [0.0359,0.0361,0.0363,0.0365,0.0367,0.0369,0.0371], \n",
    "              'kernel': ['rbf'],\n",
    "              'degree': [3]}  \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "print('Result of the best model on the test set: ', grid_predictions)\n",
    "print(grid.best_params_) \n",
    "\n",
    "a = '''\n",
    "besto_model = SVC(C=10, gamma=0.1, kernel='rbf')\n",
    "model = besto_model\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "test_acc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9499381953028431"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "besto_model = SVC(C=10, gamma=0.0362, kernel='rbf')\n",
    "model = besto_model\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "  \n",
    "# defining parameter range \n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors': list(range(89,90)),\n",
    "              'weights':['uniform','distance'],\n",
    "              'algorithm':['ball_tree','kd_tree','brute','auto'],\n",
    "              'p':list(range(1,3)),\n",
    "              'metric':['cityblock','cosine', 'euclidean', 'haversine', 'l1', 'l2', 'manhattan', 'nan_euclidean']}  \n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "print('Result of the best model on the test set: ', grid_predictions)\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'brute', 'metric': 'cosine', 'n_neighbors': 89, 'p': 1, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7657601977750309"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "besto_model = KNeighborsClassifier(algorithm = 'brute',metric='cosine',weights='distance', n_neighbors= 89, p= 1)\n",
    "model = besto_model\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "  \n",
    "# defining parameter range \n",
    "depths = list(range(1, 100))\n",
    "param_grid = {'max_depth': depths}  \n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GBC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    " \n",
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "  \n",
    "# defining parameter range \n",
    "a='''param_grid = {'learning_rate': [0.01, 0.03, 0.06, 0.1, 0.15, 0.2, 0.25, 0.300000012, 0.4, 0.5, 0.6, 0.7],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150]}'''\n",
    "\n",
    "param_grid = {'learning_rate': [1.0],\n",
    "              'max_depth': [5,6,7,8,9,10,11,12,13,14],\n",
    "              'n_estimators': [50,65,80,100,115,130,150]}\n",
    "              \n",
    "grid = GridSearchCV(GradientBoostingClassifier(), param_grid, refit = True, verbose = 3, n_jobs= -1) \n",
    "  \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the best model on the test set:  0.9237818181818181\n",
      "{'n_neighbors': 3}\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "model = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of the best model on the test set:  0.8603213844252163\n",
      "{'learning_rate': 1.0, 'max_depth': 12, 'n_estimators': 80}\n",
      "Result of the best model on the test set:  0.8331273176761433\n"
     ]
    }
   ],
   "source": [
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = grid.predict(X_test)\n",
    "test_acc = grid.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)\n",
    "print(grid.best_params_)\n",
    "model = GradientBoostingClassifier(learning_rate= 0.01,  max_depth= 12, n_estimators= 500)\n",
    "model.fit(X_train, y_train) \n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning \n",
    "#print(grid.best_estimator_) \n",
    "grid_predictions = model.predict(X_test)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "print('Result of the best model on the test set: ', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yurteri's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p_better = []\n",
    "for i in range(len(accuracies) - 1):\n",
    "    delta = accuracies[i+1] - accuracies[i]\n",
    "    if delta <= 0:\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        p_better.append(p_all[i])\n",
    "\n",
    "data = data_preparation(selected_channels=selected_channels, selected_labels=selected_labels, feature_subset=p_better)\n",
    "for model in models:\n",
    "    training, test = model_training(data, model, stats=False, cm=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,len(accuracies),len(accuracies)), accuracies)\n",
    "plt.legend()\n",
    "plt.savefig('foo.png', bbox_inches='tight')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.legend(['GBC', 'K-NN', 'SVM', 'DTC', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReliefF import ReliefF\n",
    "dataset = data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "X = np.concatenate([X_train, X_test])\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "fs = ReliefF(n_neighbors=1, n_features_to_keep=79)\n",
    "rf = fs.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = pd.DataFrame(columns=dataset.columns[1:80])\n",
    "for idx, col in enumerate(rf_scores.columns):\n",
    "    rf_scores[col] = rf[:][idx]\n",
    "rf_scores.to_csv('rf scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils, selection, training, constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature dataset as a dataframe\n",
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "\n",
    "#channel subsets\n",
    "#test_channels_1 = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "#test_channels_2 = [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "#test_channels_3 = [\"Cz\",\"CP3\",\"CPz\",\"P3\",\"FT7\",\"FC3\",\"FCZ\",\"FC4\",\"C4\",\"CP4\",\"TP8\",\"T5\",\"PZ\",\"T6\",\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "dataset = utils.data_loader(constants.MAIN_CSV_FILE)\n",
    "#reduced_dataset_all = utils.channel_selection(dataset, channel_names)\n",
    "reduced_dataset_target = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "#reduced_dataset_1 = utils.channel_selection(dataset, test_channels_1)\n",
    "#reduced_dataset_1 = utils.channel_selection(dataset, test_channels_1)\n",
    "#reduced_dataset_2 = utils.channel_selection(dataset, test_channels_2)\n",
    "#reduced_dataset_3 = utils.channel_selection(dataset, test_channels_3)\n",
    "\n",
    "#all_features = reduced_dataset_all.columns[:len(reduced_dataset_all.columns) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Channel Training+Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = incremental_training(dataset=dataset, channel_list=channel_list, feature_subset=all_features, models=['K-NN'], mode='feature', save=True)\n",
    "#calculate accuracy for each channel\n",
    "for channel in channel_names:\n",
    "    print(channel)\n",
    "    models = ['K-NN', 'GBC']\n",
    "    dataset = utils.data_loader(csv_file)\n",
    "    reduced_dataset = utils.channel_selection(dataset, [channel])\n",
    "    data = training.data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "    for model in models:\n",
    "        model_training(data, model, stats=False, cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "\n",
    "feature_subsets['hjorth_features'] = ['activity', 'mobility', 'complexity']\n",
    "\n",
    "feature_subsets['stat_features'] = ['skew', 'kurtosis', 'rms', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['time_features'] = feature_subsets['hjorth_features'] + feature_subsets['stat_features']\n",
    "\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['spec_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2', 'mel_3', 'mel_4', 'mel_5'] + ['energy_mel_5','energy_mel_4', 'energy_mel_3', 'energy_mel_2', 'energy_mel_1', 'energy_mel_0']\n",
    "       \n",
    "feature_subsets['coeff_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['freq_features'] = feature_subsets['spectral_features'] + feature_subsets['coeff_features']\n",
    "\n",
    "feature_subsets['all'] = feature_subsets['freq_features'] + feature_subsets['time_features']\n",
    "\n",
    "# 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10', 'mel_11', 'mel_12', 'mel_13', 'mel_14', 'mel_15', 'mel_16', 'mel_17'\n",
    "#feature_subsets['chr_features'] = ['chr_0', 'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8', 'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15', 'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "#feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "#feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset_target, feature_subset=feature_subsets['all'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "chi2_stats, p_values = chi2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['all']):\n",
    "    chi2_dict[feature] = chi2_stats[idx]\n",
    "chi_sorted = dict(sorted(chi2_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "chi_sorted_list = list(chi_sorted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['complexity', 'alpha_power', 'energy_mel_4', 'energy_mel_2', 'energy_mel_5', 'spc_roff', 'mel_4', 'energy_mel_3', 'mel_2', 'mel_3', 'energy_mel_1', 'mel_5', 'spc_cnt', 'gamma_beta', 'mel_1', 'theta_power', 'rms', 'beta_alpha', 'gamma_alpha', 'alpha_delta', 'mfcc_8', 'mobility', 'mfcc_2', 'energy_mel_0', 'mel_0', 'mfcc_3', 'mfcc_6', 'alpha_theta', 'mfcc_0', 'gamma_theta', 'delta_power', 'mean_abs_sec_dif', 'zc', 'mfcc_1', 'gamma_delta', 'activity', 'dfa', 'mfcc_5', 'beta_theta', 'theta_delta', 'mfcc_4', 'beta_power', 'mfcc_7', 'gamma_power', 'mfcc_9', 'skew', 'slope', 'beta_delta', 'kurtosis']\n"
     ]
    }
   ],
   "source": [
    "print(chi_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'complexity': 94.28211862279358,\n",
       " 'alpha_power': 61.61758765555503,\n",
       " 'energy_mel_4': 55.966792942887594,\n",
       " 'energy_mel_2': 50.35524485210654,\n",
       " 'energy_mel_5': 49.049443325165676,\n",
       " 'spc_roff': 45.335745653110536,\n",
       " 'mel_4': 44.463207191022846,\n",
       " 'energy_mel_3': 44.17877030308956,\n",
       " 'mel_2': 44.16600415763707,\n",
       " 'mel_3': 37.11520689875526,\n",
       " 'energy_mel_1': 37.06779659270134,\n",
       " 'mel_5': 36.71753654732982,\n",
       " 'spc_cnt': 32.83364136602729,\n",
       " 'gamma_beta': 32.70304573869533,\n",
       " 'mel_1': 31.22485063759271,\n",
       " 'theta_power': 30.496223978846125,\n",
       " 'rms': 24.313244174897562,\n",
       " 'beta_alpha': 23.22056404804195,\n",
       " 'gamma_alpha': 22.58373946911419,\n",
       " 'alpha_delta': 20.175210830953596,\n",
       " 'mfcc_8': 19.043161553563458,\n",
       " 'mobility': 17.024258058956406,\n",
       " 'mfcc_2': 16.639397142777554,\n",
       " 'energy_mel_0': 15.08055575705373,\n",
       " 'mel_0': 14.893527655872292,\n",
       " 'mfcc_3': 14.875414600070316,\n",
       " 'mfcc_6': 11.93753593845356,\n",
       " 'alpha_theta': 11.095610187638865,\n",
       " 'mfcc_0': 10.901002678919598,\n",
       " 'gamma_theta': 9.11242206872141,\n",
       " 'delta_power': 8.701726131164731,\n",
       " 'mean_abs_sec_dif': 8.02698728446344,\n",
       " 'zc': 7.055753967309026,\n",
       " 'mfcc_1': 6.131827007644796,\n",
       " 'gamma_delta': 5.964851215484087,\n",
       " 'activity': 5.699315565046817,\n",
       " 'dfa': 5.670523404339953,\n",
       " 'mfcc_5': 4.487480478934759,\n",
       " 'beta_theta': 4.372249509433937,\n",
       " 'theta_delta': 2.9816120211729213,\n",
       " 'mfcc_4': 2.106270968103849,\n",
       " 'beta_power': 2.0891492594157905,\n",
       " 'mfcc_7': 1.856598205913659,\n",
       " 'gamma_power': 0.8955821607570242,\n",
       " 'mfcc_9': 0.28175269168179795,\n",
       " 'skew': 0.25359514769785774,\n",
       " 'slope': 0.05053956226214974,\n",
       " 'beta_delta': 0.005567609826478443,\n",
       " 'kurtosis': 0.00011142454858883223}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_df, variance_dict = selection.variance_thresholding(reduced_dataset_target, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset_target, feature_subset=feature_subsets['all'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "f_statistic, p_values = f_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['all']):\n",
    "    f_dict[feature] = f_statistic[idx]\n",
    "f_sorted = dict(sorted(f_dict.items(), key=lambda item: item[1], reverse=True)) \n",
    "anova_sorted_list = list(f_sorted.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['energy_mel_2', 'mel_2', 'mel_3', 'energy_mel_1', 'energy_mel_3', 'energy_mel_4', 'mel_1', 'mel_4', 'spc_roff', 'complexity', 'energy_mel_5', 'mel_5', 'rms', 'spc_cnt', 'alpha_power', 'theta_power', 'mfcc_8', 'mfcc_2', 'gamma_beta', 'mel_0', 'energy_mel_0', 'mfcc_3', 'mobility', 'mfcc_0', 'mfcc_6', 'zc', 'dfa', 'mean_abs_sec_dif', 'beta_alpha', 'alpha_delta', 'mfcc_1', 'gamma_alpha', 'delta_power', 'alpha_theta', 'gamma_theta', 'activity', 'mfcc_5', 'gamma_delta', 'mfcc_4', 'beta_theta', 'skew', 'beta_power', 'theta_delta', 'mfcc_7', 'slope', 'mfcc_9', 'gamma_power', 'beta_delta', 'kurtosis']\n"
     ]
    }
   ],
   "source": [
    "print(anova_sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy_mel_2': 1716.6963971410814,\n",
       " 'mel_2': 1683.5683365035482,\n",
       " 'mel_3': 1270.7767147420525,\n",
       " 'energy_mel_1': 1270.0349458609455,\n",
       " 'energy_mel_3': 1265.4877095361082,\n",
       " 'energy_mel_4': 1256.9155811020325,\n",
       " 'mel_1': 1243.8409361591785,\n",
       " 'mel_4': 1234.9127960983778,\n",
       " 'spc_roff': 1179.7978846086457,\n",
       " 'complexity': 1171.7471438323403,\n",
       " 'energy_mel_5': 1117.4046251154236,\n",
       " 'mel_5': 1112.9821347972538,\n",
       " 'rms': 724.8313528466713,\n",
       " 'spc_cnt': 717.5656346396394,\n",
       " 'alpha_power': 674.0351116859352,\n",
       " 'theta_power': 659.5643477476857,\n",
       " 'mfcc_8': 541.3803847829643,\n",
       " 'mfcc_2': 457.90180619721406,\n",
       " 'gamma_beta': 427.447151720878,\n",
       " 'mel_0': 419.34135497630484,\n",
       " 'energy_mel_0': 388.9095010390218,\n",
       " 'mfcc_3': 360.7109153467148,\n",
       " 'mobility': 347.54850066696844,\n",
       " 'mfcc_0': 332.5889617866217,\n",
       " 'mfcc_6': 326.9010075256607,\n",
       " 'zc': 265.2214986783893,\n",
       " 'dfa': 256.86395209632826,\n",
       " 'mean_abs_sec_dif': 256.2064104997069,\n",
       " 'beta_alpha': 249.9364197046969,\n",
       " 'alpha_delta': 223.31895499403223,\n",
       " 'mfcc_1': 222.73801619514165,\n",
       " 'gamma_alpha': 221.68789062284523,\n",
       " 'delta_power': 189.2474738596258,\n",
       " 'alpha_theta': 140.9986051514596,\n",
       " 'gamma_theta': 139.22779913445612,\n",
       " 'activity': 124.0122160250325,\n",
       " 'mfcc_5': 114.55056121280379,\n",
       " 'gamma_delta': 87.24797171945627,\n",
       " 'mfcc_4': 85.58181451224722,\n",
       " 'beta_theta': 76.57521864315764,\n",
       " 'skew': 61.96560616337139,\n",
       " 'beta_power': 58.20123475753126,\n",
       " 'theta_delta': 56.42518069770956,\n",
       " 'mfcc_7': 51.3197895207797,\n",
       " 'slope': 32.35195583222613,\n",
       " 'mfcc_9': 13.58329138398489,\n",
       " 'gamma_power': 9.3810936784867,\n",
       " 'beta_delta': 0.06262726708156617,\n",
       " 'kurtosis': 0.0034415002002849025}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7527047913446677\n",
      "Test Accuracy:  0.7435105067985167\n",
      "Sensitivity (Recall): 0.7391304347826086\n",
      "Precision: 0.74375\n",
      "F1_score: 0.7414330218068534\n",
      "AUC: 0.7434889566286967\n",
      "Logloss: 9.244818390904586\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.927070457354759\n",
      "Sensitivity (Recall): 0.9465838509316771\n",
      "Precision: 0.910394265232975\n",
      "F1_score: 0.9281364190012181\n",
      "AUC: 0.9271664642112261\n",
      "Logloss: 2.6286471569319065\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.8360123647604327\n",
      "Test Accuracy:  0.7571075401730532\n",
      "Sensitivity (Recall): 0.7751552795031056\n",
      "Precision: 0.7464114832535885\n",
      "F1_score: 0.7605118829981717\n",
      "AUC: 0.7571963359385147\n",
      "Logloss: 8.754731632832534\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8331273176761433\n",
      "Sensitivity (Recall): 0.8596273291925466\n",
      "Precision: 0.8150765606595995\n",
      "F1_score: 0.8367593712212817\n",
      "AUC: 0.8332576990366177\n",
      "Logloss: 6.014701121793346\n",
      "\n",
      "\n",
      "==== Stats_dict for the LR model ====\n",
      "Training Accuracy:  0.7678516228748068\n",
      "Test Accuracy:  0.7472187886279357\n",
      "Sensitivity (Recall): 0.7639751552795031\n",
      "Precision: 0.737410071942446\n",
      "F1_score: 0.7504575960951799\n",
      "AUC: 0.7473012307762829\n",
      "Logloss: 9.111158365975843\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.9901081916537867\n",
      "Test Accuracy:  0.8257107540173053\n",
      "Sensitivity (Recall): 0.8260869565217391\n",
      "Precision: 0.8240396530359355\n",
      "F1_score: 0.825062034739454\n",
      "AUC: 0.8257126049521366\n",
      "Logloss: 6.282021171650826\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8473423980222496\n",
      "Sensitivity (Recall): 0.8645962732919255\n",
      "Precision: 0.8345323741007195\n",
      "F1_score: 0.8492983526540574\n",
      "AUC: 0.8474272879374757\n",
      "Logloss: 5.502337692899837\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anova_selected = ['spc_roff', 'complexity', 'mel_11', 'mel_10', 'mel_6', 'mel_7', 'mel_12', 'mel_9', 'mel_8', 'mel_14', 'mel_13', 'rms', 'spc_cnt', 'mel_5', 'alpha_power', 'theta_power', 'mfcc_8', 'mfcc_2', 'gamma_beta', 'mel_4', 'mfcc_3', 'mel_3', 'mobility', 'mfcc_0', 'mfcc_6', 'mel_2', 'mel_1', 'zc', 'mean_abs_sec_dif', 'dfa', 'beta_alpha', 'alpha_delta', 'mfcc_1', 'gamma_alpha', 'mel_0', 'delta_power', 'alpha_theta', 'gamma_theta', 'activity', 'mfcc_5', 'gamma_delta', 'mfcc_4', 'beta_theta', 'skew', 'beta_power', 'theta_delta', 'mfcc_7', 'slope']\n",
    "data = training.data_preparation(dataset=reduced_dataset_target, feature_subset=anova_selected)\n",
    "for model in constants.ALL_MODELS:\n",
    "    training.model_training(data, model, stats=True, cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Value Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n"
     ]
    }
   ],
   "source": [
    "channel_subsets = [channel_names, test_channels_1, test_channels_2, test_channels_3]\n",
    "subset_names = ['chn_all', 'chn_1', 'chn_2', 'chn_3']\n",
    "p_val_df = pd.DataFrame(columns=subset_names)\n",
    "\n",
    "for i in range(len(channel_subsets)):\n",
    "    dataset = data_loader(csv_file)\n",
    "    reduced_dataset_i = utils.channel_selection(dataset, channel_subsets[i])\n",
    "    p_i, p_i_val = selcetion.p_value_thresholding(reduced_dataset_i, feature_subset=all_features)\n",
    "    p_val_df[subset_names[i]] = p_i_val    \n",
    "\n",
    "p_val_df.to_csv('outs/p_values_by_channels.csv')\n",
    "\n",
    "a='''\n",
    "p_all, p_all_val = p_value_thresholding(reduced_dataset_all, feature_subset=all_features)\n",
    "    p_1, p_1_val = p_value_thresholding(reduced_dataset_1, feature_subset=all_features)\n",
    "    p_2, p_2_val = p_value_thresholding(reduced_dataset_2, feature_subset=all_features)\n",
    "    p_3, p_3_val = p_value_thresholding(reduced_dataset_3, feature_subset=all_features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yurteri's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_better = []\n",
    "for i in range(len(accuracies) - 1):\n",
    "    delta = accuracies[i+1] - accuracies[i]\n",
    "    if delta <= 0:\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        p_better.append(p_all[i])\n",
    "\n",
    "data = data_preparation(selected_channels=selected_channels, selected_labels=selected_labels, feature_subset=p_better)\n",
    "for model in models:\n",
    "    training, test = model_training(data, model, stats=False, cm=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,len(accuracies),len(accuracies)), accuracies)\n",
    "plt.legend()\n",
    "plt.savefig('foo.png', bbox_inches='tight')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.legend(['GBC', 'K-NN', 'SVM', 'DTC', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReliefF import ReliefF\n",
    "dataset = utils.data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = utils.channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "X = np.concatenate([X_train, X_test])\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "fs = ReliefF(n_neighbors=1, n_features_to_keep=79)\n",
    "rf = fs.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = pd.DataFrame(columns=dataset.columns[1:80])\n",
    "for idx, col in enumerate(rf_scores.columns):\n",
    "    rf_scores[col] = rf[:][idx]\n",
    "rf_scores.to_csv('rf scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

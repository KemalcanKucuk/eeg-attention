{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils, selection, training, constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O - Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the feature dataset as a dataframe\n",
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "\n",
    "#channel subsets\n",
    "test_channels_1 = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "test_channels_2 =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "test_channels_3 = [\"Cz\",\"CP3\",\"CPz\",\"P3\",\"FT7\",\"FC3\",\"FCZ\",\"FC4\",\"C4\",\"CP4\",\"TP8\",\"T5\",\"PZ\",\"T6\",\"O1\",\"Oz\",\"O2\"]\n",
    "\n",
    "csv_file = 'eeg_features.csv'\n",
    "\n",
    "dataset = data_loader(csv_file)\n",
    "reduced_dataset_all = utils.channel_selection(dataset, channel_names)\n",
    "reduced_dataset_1 = utils.channel_selection(dataset, test_channels_1)\n",
    "reduced_dataset_1 = utils.channel_selection(dataset, test_channels_1)\n",
    "reduced_dataset_2 = utils.channel_selection(dataset, test_channels_2)\n",
    "reduced_dataset_3 = utils.channel_selection(dataset, test_channels_3)\n",
    "\n",
    "all_features = reduced_dataset_all.columns[:len(reduced_dataset_all.columns) - 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Channel Training+Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = incremental_training(dataset=dataset, channel_list=channel_list, feature_subset=all_features, models=['K-NN'], mode='feature', save=True)\n",
    "#calculate accuracy for each channel\n",
    "for channel in channel_names:\n",
    "    print(channel)\n",
    "    models = ['K-NN', 'GBC']\n",
    "    dataset = utils.data_loader(csv_file)\n",
    "    reduced_dataset = utils.channel_selection(dataset, [channel])\n",
    "    data = training.data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "    for model in models:\n",
    "        model_training(data, model, stats=False, cm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['time_features'] = ['skew', 'kurtosis', 'rms', 'activity', 'mobility', 'complexity', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['freq_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
    "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2',\n",
    "               'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10',\n",
    "               'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['chr_features'] = ['chr_0',\n",
    "                'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8',\n",
    "                'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15',\n",
    "                'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "feature_subsets['coeffs'] = feature_subsets['spectral_features'] + feature_subsets['music']\n",
    "\n",
    "feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "feature_subsets['no_music'] = feature_subsets['spectral_features'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset_1, feature_subset=feature_subsets['no_music'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "chi2_stats, p_values = chi2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['no_music']):\n",
    "    chi2_dict[feature] = chi2_stats[idx]\n",
    "chi_sorted = dict(sorted(chi2_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'spc_cnt': 0.017052328672271307, 'spc_roff': 0.02147142065322427, 'zc': 0.01172474049559578, 'mfcc_0': 0.01203708673791313, 'mfcc_1': 0.014112929451190314, 'mfcc_2': 0.021941784940100274, 'mfcc_3': 0.017817116238044623, 'mfcc_4': 0.0126894761088686, 'mfcc_5': 0.017037658767643196, 'mfcc_6': 0.019355834030006385, 'mfcc_7': 0.018912060293347157, 'mfcc_8': 0.0171567166429845, 'mfcc_9': 0.0115739794267946, 'mel_0': 0.010996040874554594, 'mel_1': 0.012921841312696471, 'mel_2': 0.016043348899490325, 'mel_3': 0.016233514887458077, 'mel_4': 0.017133762682894096, 'mel_5': 0.01364072945989802, 'mel_6': 0.014638942205991646, 'mel_7': 0.017393951472625555, 'mel_8': 0.01860756243251427, 'mel_9': 0.015581871424765446, 'mel_10': 0.015816972579750364, 'mel_11': 0.012323108190702831, 'mel_12': 0.014616789245175392, 'mel_13': 0.015715943503232282, 'mel_14': 0.019322444896845405, 'delta_power': 0.0017565775998420942, 'theta_power': 0.001632270177915374, 'alpha_power': 0.0050050474475379905, 'beta_power': 0.0005669046053166077, 'gamma_power': 0.0006290085393331012, 'gamma_beta': 0.011367199092663826, 'gamma_alpha': 0.003749209566276582, 'gamma_theta': 0.0011396155293642409, 'gamma_delta': 0.0015416622831965327, 'beta_alpha': 0.009263343933817324, 'beta_theta': 0.0033261993645024965, 'beta_delta': 0.00640916959502327, 'alpha_theta': 0.004276523340518105, 'alpha_delta': 0.004105734253660745, 'theta_delta': 0.0018495685365383199, 'mean_abs_sec_dif': 0.0026568605107117334, 'dfa': 0.013083941373154172, 'slope': 0.0009768614003247242, 'skew': 0.002356505752027207, 'kurtosis': 0.001497651426392435, 'activity': 0.0009641851985528873, 'mobility': 0.009733945293089526, 'complexity': 0.026096167890401034, 'rms': 0.0035494960304538374, 'subjects': 0.09940864144264722, 'label': 0.25}\n"
     ]
    }
   ],
   "source": [
    "variance_df, variance_dict = selection.variance_thresholding(reduced_dataset_1, threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset_1, feature_subset=feature_subsets['no_music'])\n",
    "X = np.concatenate([X_train, X_test])\n",
    "X = scaler.fit_transform(X)\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "\n",
    "f_statistic, p_values = f_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_dict = {}\n",
    "for idx, feature in enumerate(feature_subsets['no_music']):\n",
    "    f_dict[feature] = f_statistic[idx]\n",
    "f_sorted = dict(sorted(f_dict.items(), key=lambda item: item[1], reverse=True)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-Value Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/selection.py:77: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  t_stat, p_value = stats.ttest_ind(\n"
     ]
    }
   ],
   "source": [
    "channel_subsets = [channel_names, test_channels_1, test_channels_2, test_channels_3]\n",
    "subset_names = ['chn_all', 'chn_1', 'chn_2', 'chn_3']\n",
    "p_val_df = pd.DataFrame(columns=subset_names)\n",
    "\n",
    "for i in range(len(channel_subsets)):\n",
    "    dataset = data_loader(csv_file)\n",
    "    reduced_dataset_i = utils.channel_selection(dataset, channel_subsets[i])\n",
    "    p_i, p_i_val = selcetion.p_value_thresholding(reduced_dataset_i, feature_subset=all_features)\n",
    "    p_val_df[subset_names[i]] = p_i_val    \n",
    "\n",
    "p_val_df.to_csv('outs/p_values_by_channels.csv')\n",
    "\n",
    "a='''\n",
    "p_all, p_all_val = p_value_thresholding(reduced_dataset_all, feature_subset=all_features)\n",
    "    p_1, p_1_val = p_value_thresholding(reduced_dataset_1, feature_subset=all_features)\n",
    "    p_2, p_2_val = p_value_thresholding(reduced_dataset_2, feature_subset=all_features)\n",
    "    p_3, p_3_val = p_value_thresholding(reduced_dataset_3, feature_subset=all_features)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of K-NN classifier on training set: 0.79962894\n",
      "Accuracy of K-NN classifier on test set: 0.66913580\n"
     ]
    }
   ],
   "source": [
    "#models = ['K-NN', 'GBC']\n",
    "models = ['K-NN']\n",
    "subset_1 = all_features\n",
    "\n",
    "data = training.data_preparation(dataset=reduced_dataset, feature_subset=subset_1, pca=True)\n",
    "for model in models:\n",
    "    training.model_training(data, model, stats=False, cm=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yurteri's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_better = []\n",
    "for i in range(len(accuracies) - 1):\n",
    "    delta = accuracies[i+1] - accuracies[i]\n",
    "    if delta <= 0:\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        p_better.append(p_all[i])\n",
    "\n",
    "data = data_preparation(selected_channels=selected_channels, selected_labels=selected_labels, feature_subset=p_better)\n",
    "for model in models:\n",
    "    training, test = model_training(data, model, stats=False, cm=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,len(accuracies),len(accuracies)), accuracies)\n",
    "plt.legend()\n",
    "plt.savefig('foo.png', bbox_inches='tight')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.legend(['GBC', 'K-NN', 'SVM', 'DTC', 'NN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReliefF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ReliefF import ReliefF\n",
    "dataset = utils.data_loader(csv_file)\n",
    "best_channel_list = ['CP3', 'Cz', 'CPz', 'P3']\n",
    "reduced_dataset = utils.channel_selection(dataset, best_channel_list)\n",
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "X = np.concatenate([X_train, X_test])\n",
    "y = np.concatenate([y_train, y_test]).flatten()\n",
    "fs = ReliefF(n_neighbors=1, n_features_to_keep=79)\n",
    "rf = fs.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_scores = pd.DataFrame(columns=dataset.columns[1:80])\n",
    "for idx, col in enumerate(rf_scores.columns):\n",
    "    rf_scores[col] = rf[:][idx]\n",
    "rf_scores.to_csv('rf scores.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

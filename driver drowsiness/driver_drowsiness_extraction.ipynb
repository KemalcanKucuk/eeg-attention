{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hedef: feature extractionda butun featurelari cikart, csvde hepsine isim ver, training datasi hazirlarken csvden ihtiyac olani kullan\n",
    "def feature_extraction(signal):\n",
    "    \n",
    "    n_mfcc = 5 \n",
    "    feature_vector = {}\n",
    "    extracted_features = []\n",
    "    # Timbral Texture Features\n",
    "    \n",
    "    # 0 indices are due to array shape\n",
    "    feature_vector['spc_cnt'] = lrf.spectral_centroid(y=signal)[0][0] # Spectral Centroid\n",
    "    feature_vector['spc_roff'] = lrf.spectral_rolloff(y=signal)[0][0] # Rolloff\n",
    "    feature_vector['zc']  = np.array(np.sum(np.abs(np.diff(np.sign(signal)))) / (2 * len(signal)))\n",
    "    \n",
    "    for idx, mfcc in enumerate(lrf.mfcc(y=signal, n_mfcc=n_mfcc)): # First 5 MFCCs\n",
    "        feature_vector['mfcc_' + str(idx)] = mfcc[0]\n",
    "    \n",
    "    for idx, chroma in enumerate(lrf.chroma_stft(y=signal, n_chroma=12)): #chromagram\n",
    "        feature_vector['chr_' + str(idx)] = chroma[0]\n",
    "\n",
    "    n_mel = 10\n",
    "    for idx, mel in enumerate(lr.power_to_db(lrf.melspectrogram(y=signal))[:n_mel, :]):\n",
    "        feature_vector['mel_' + str(idx)] = mel[0]\n",
    "\n",
    "    frequency_bands = {\n",
    "    'gamma': (30,64),\n",
    "    'beta': (13, 30),\n",
    "    'alpha': (8, 13),\n",
    "    'theta': (4, 8),\n",
    "    'delta': (1, 4),\n",
    "    }\n",
    "\n",
    "    # Iterate over each frequency band\n",
    "    band_powers = {}\n",
    "    sampling_frequency = 128\n",
    "\n",
    "    # Calculate the power spectral density (PSD) using Welch's method\n",
    "    frequencies, psd = welch(signal, fs=sampling_frequency, nperseg=1024)\n",
    "\n",
    "    # Iterate over each frequency band\n",
    "    for band, (low_freq, high_freq) in frequency_bands.items():\n",
    "        # Find indices corresponding to the specified frequency range\n",
    "        band_indices = np.where((frequencies >= low_freq) & (frequencies < high_freq))\n",
    "        # Integrate PSD within the band's frequency range to compute band power\n",
    "        band_power = np.trapz(psd[band_indices], frequencies[band_indices])\n",
    "        band_powers[band] = band_power\n",
    "        feature_vector[band + '_power'] = band_power\n",
    "    \n",
    "    for band in list(band_powers):\n",
    "        for child_band in list(band_powers):\n",
    "            if child_band == band:\n",
    "                continue\n",
    "            feature_vector[band + '_' + child_band] = band_powers[band] / band_powers[child_band]\n",
    "        band_powers.pop(band)\n",
    "    \n",
    "    \n",
    "    return feature_vector\n",
    "    \n",
    "    # rejected features, discuss whether to include them in the paper or not.\n",
    "\n",
    "    #feature_vector.append([np.mean(signal)]) #no\n",
    "    #feature_vector.append([np.var(signal)]) #no\n",
    "    #feature_vector.append([stats.skew(signal)]) #no\n",
    "    #feature_vector.append([stats.kurtosis(signal)]) #no\n",
    "\n",
    "    #activity, mobility, complexity = hjorth_parameters(signal) #no\n",
    "    #feature_vector.append([activity]) #no\n",
    "    #feature_vector.append([mobility]) #no\n",
    "    #feature_vector.append([complexity]) #no\n",
    "\n",
    "    #feature_vector.append([np.sqrt(np.mean(signal**2))]) #no\n",
    "    #feature_vector.append(lr.beat.tempo(signal)) # Tempo #bu kötü yapiyor\n",
    "\n",
    "    #for tonal in lrf.tonnetz(signal)[:n_tonnetz, :] : #daha kötü gibi\n",
    "    #    feature_vector.append(tonal)\n",
    "    '''\n",
    "    [cA5, cD5, cD4, cD3, cD2, cD1] = wavedec(signal, 'db1', level=5)\n",
    "    coeffs = [cA5, cD5, cD4, cD3, cD2, cD1]\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    \n",
    "    re0 = pywt.waverec([coeffs[0]], db1)\n",
    "    re1 = pywt.waverec([coeffs[1]], db1)\n",
    "    re2 = pywt.waverec([coeffs[2]], db1)\n",
    "    re3 = pywt.waverec([coeffs[3]], db1)\n",
    "    re4 = pywt.waverec([coeffs[4]], db1)\n",
    "    re5 = pywt.waverec([coeffs[5]], db1)\n",
    "\n",
    "    re0_p = np.sum(np.power(re0,2)/len(re0))\n",
    "    re1_p = np.sum(np.power(re1,2)/len(re1))\n",
    "    re2_p = np.sum(np.power(re2,2)/len(re2))\n",
    "    re3_p = np.sum(np.power(re3,2)/len(re3))\n",
    "    re4_p = np.sum(np.power(re4,2)/len(re4))\n",
    "    re5_p = np.sum(np.power(re5,2)/len(re5))\n",
    "    \n",
    "    feature_vector.append([[re0_p]])\n",
    "    feature_vector.append([[re1_p]])\n",
    "    feature_vector.append([[re2_p]])\n",
    "    feature_vector.append([[re3_p]])\n",
    "    feature_vector.append([[re4_p]])\n",
    "    feature_vector.append([[re5_p]])\n",
    "    \n",
    "    feature_vector.append([[re5_p/re4_p]])\n",
    "    feature_vector.append([[re5_p/re3_p]])\n",
    "    feature_vector.append([[re5_p/re2_p]])\n",
    "    feature_vector.append([[re5_p/re1_p]])\n",
    "    feature_vector.append([[re5_p/re0_p]])\n",
    "    feature_vector.append([[re4_p/re3_p]])\n",
    "    feature_vector.append([[re4_p/re2_p]])\n",
    "    feature_vector.append([[re4_p/re1_p]])\n",
    "    feature_vector.append([[re4_p/re0_p]])\n",
    "    feature_vector.append([[re3_p/re2_p]])\n",
    "    feature_vector.append([[re3_p/re1_p]])\n",
    "    feature_vector.append([[re3_p/re0_p]])\n",
    "    feature_vector.append([[re2_p/re1_p]])\n",
    "    feature_vector.append([[re2_p/re0_p]])\n",
    "    feature_vector.append([[re1_p/re0_p]])\n",
    "    '''\n",
    "\n",
    "\n",
    "    # hata veren featureler\n",
    "\n",
    "    '''    \n",
    "    \n",
    "    # Rhythymic Content Features\n",
    "    peaks = -np.sort(-lr.onset.onset_strength(signal, sr = 128))\n",
    "    A0 = peaks[0]\n",
    "    A1 = peaks[1]\n",
    "    RA = A1/A0    \n",
    "    \n",
    "    extracted_features.append(np.mean(lrf.tempogram(signal)))\n",
    "    extracted_features.append(A0)\n",
    "    extracted_features.append(A1)\n",
    "    extracted_features.append(RA)\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    #feature_vector.append([lr.onset.onset_strength(signal)]) # Flux\n",
    "    #feature_vector.append(lr.feature.zero_crossing_rate(signal)) # Zero Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/Users/kemalcankucuk/Documents/PAWS Work/drowsiness-dataset.mat'\n",
    "data_dict = scipy.io.loadmat(dataset_path)\n",
    "\n",
    "subjects = list(data_dict[\"subindex\"])\n",
    "states = [i[0] for i in data_dict[\"substate\"]]\n",
    "eeg = data_dict[\"EEGsample\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "channel_idx =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "channel_names = dict(zip(channel_names, channel_idx))\n",
    "\n",
    "def select_channel(data, channel_list):\n",
    "    selection = []\n",
    "    channel_col = []\n",
    "    for i in range(len(channel_list)):\n",
    "        selection.append(data[:, channel_names[channel_list[i]], :])\n",
    "        channel_col.append([channel_list[i]] * data.shape[0])\n",
    "    selected_data = np.concatenate(selection)\n",
    "    channel_col = np.concatenate(channel_col)\n",
    "    return selected_data, channel_col\n",
    "\n",
    "channel_list = ['F3', 'F4', 'C3', 'C4', 'Oz']\n",
    "labels = states * len(channel_list)\n",
    "data, channel_col = select_channel(eeg, channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction on Selected Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.51409792900085\n"
     ]
    }
   ],
   "source": [
    "# extracted features np array olabilir liste yerine\n",
    "import time\n",
    "start = time.time()\n",
    "extracted_features = []\n",
    "for i in range(data.shape[0]):\n",
    "    signal_features = feature_extraction(data[i,:])\n",
    "    extracted_features.append(signal_features)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(extracted_features).fillna(0)\n",
    "df.insert(loc = 0, column = 'channels', value = channel_col)\n",
    "df['label'] = labels\n",
    "df.to_csv(\"eeg_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'boncuk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/driver drowsiness/driver_drowsiness_extraction.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kemalcankucuk/Documents/PAWS%20Work/eeg-attention/driver%20drowsiness/driver_drowsiness_extraction.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m boncuk\n",
      "\u001b[0;31mNameError\u001b[0m: name 'boncuk' is not defined"
     ]
    }
   ],
   "source": [
    "boncuk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

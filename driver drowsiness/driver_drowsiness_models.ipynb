{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from ipynb.fs.full.driver_drowsiness_extraction import select_channel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'eeg_features.csv'\n",
    "df = pd.read_csv(csv_file,float_precision='round_trip')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop('label', axis=1)\n",
    "labels = df.iloc[:,-1:]\n",
    "display_labels = ['drowsy' if label == 1 else 'alert' for label in labels['label'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_training(features, labels, channel_list):\n",
    "    found_channels = []\n",
    "    for channel in channel_list:\n",
    "        found_channels.append(features.loc[df['channels'] == channel])\n",
    "    return (pd.concat(found_channels).drop('channels', axis=1)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_list = ['F3', 'F4','C3','Cz','Oz']\n",
    "X = channel_training(features=features, labels=labels, channel_list=channel_list)\n",
    "y = labels[0:2022*len(channel_list)].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=1)\n",
    "\n",
    "# apply normalization after splitting to avoid leakage\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "def model_training(model_family, display_labels, stats=False, cm=False):\n",
    "\n",
    "  if model_family == 'K-NN':\n",
    "    model = KNeighborsClassifier()\n",
    "  elif model_family == 'DTC':\n",
    "    model = DecisionTreeClassifier()\n",
    "  elif model_family == 'RFC':\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "  elif model_family == 'Logistic Regression':\n",
    "    model = LogisticRegression(max_iter=5000)\n",
    "  elif model_family == 'SVM':\n",
    "    model = SVC(C=1.0, kernel='rbf', degree=10, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=1)\n",
    "  elif model_family == 'NN':\n",
    "    model = MLPClassifier(activation='relu',solver='adam', alpha=1e-2, learning_rate='adaptive', max_iter=1000000, hidden_layer_sizes=(60,2), random_state=1)\n",
    "  elif model_family == 'GBC':\n",
    "    model = GradientBoostingClassifier(loss='log_loss',n_estimators=300, learning_rate=0.1, max_depth=10, random_state=1)\n",
    "\n",
    "  model.fit(X_train, y_train)\n",
    "  print('Accuracy of {} classifier on training set: {:.8f}'\n",
    "     .format(model_family, model.score(X_train, y_train)))\n",
    "  print('Accuracy of {} classifier on test set: {:.8f}'\n",
    "     .format(model_family, model.score(X_test, y_test)))\n",
    "\n",
    "  if stats:\n",
    "    print()\n",
    "    print(\"==== Stats for the {} model ====\".format(model_family))\n",
    "    sensitivity = recall_score(y_test, model.predict(X_test))\n",
    "    print(\"Sensitivity (Recall):\", sensitivity)\n",
    "\n",
    "    precision = precision_score(y_test, model.predict(X_test))\n",
    "    print(\"Precision:\", precision)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    print(\"Accuracy (Recall):\", accuracy)\n",
    "        \n",
    "    f1 = f1_score(y_test, model.predict(X_test))\n",
    "    print(\"F1_score:\", f1)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, model.predict(X_test))\n",
    "    auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "    print(\"AUC:\", auc)\n",
    "\n",
    "    logloss = log_loss(y_test, model.predict(X_test))\n",
    "    print(\"Logloss:\", logloss)\n",
    "    print()\n",
    "\n",
    "  if cm:\n",
    "    model_cm = confusion_matrix(y_test, model.predict(X_test))\n",
    "    model_disp = ConfusionMatrixDisplay(confusion_matrix=model_cm,display_labels=display_labels)\n",
    "    model_disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GBC classifier on training set: 1.00000000\n",
      "Accuracy of GBC classifier on test set: 0.81651830\n",
      "\n",
      "==== Stats for the GBC model ====\n",
      "Sensitivity (Recall): 0.7928994082840237\n",
      "Precision: 0.8331606217616581\n",
      "Accuracy (Recall): 0.8165182987141444\n",
      "F1_score: 0.8125315816068721\n",
      "AUC: 0.8165885930309008\n",
      "Logloss: 6.337297120523306\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = ['GBC']\n",
    "for model in models:\n",
    "    model_training(model, display_labels, stats=True, cm=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.decomposition import PCA\\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\\n\\n#y = y.reset_index(drop=True)\\n\\npca = PCA(n_components = 0.999)\\nX_train = pca.fit_transform(X_train)\\nX_test = pca.transform(X_test)\\n#X = dataPCA\\nvariance = pd.DataFrame(pca.explained_variance_ratio_)\\nprint(pca.explained_variance_ratio_)\\nprint(np.sum(pca.explained_variance_ratio_))\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "#y = y.reset_index(drop=True)\n",
    "\n",
    "pca = PCA(n_components = 0.999)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "#X = dataPCA\n",
    "variance = pd.DataFrame(pca.explained_variance_ratio_)\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(np.sum(pca.explained_variance_ratio_))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = []\n",
    "\n",
    "X_p = df.drop('channels',axis = 1)\n",
    "X_p = X_p.drop('label',axis = 1)\n",
    "\n",
    "#y_p = pd.Series(y['0'])\n",
    "for feature in X_p.columns:\n",
    "    t_stat, p_value = stats.ttest_ind(X_p[feature][y_p == 0], X_p[feature][y_p == 1])\n",
    "    p_values.append(p_value)\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "# Select features with p-values below the significance level\n",
    "selected_features = [X_p.columns[i] for i, p in enumerate(p_values) if p < alpha]\n",
    "# Alternatively, you can rank features by p-value\n",
    "sorted_features = [x for _, x in sorted(zip(p_values, X_p.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spc_cnt</th>\n",
       "      <th>spc_roff</th>\n",
       "      <th>zc</th>\n",
       "      <th>mfcc_0</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>chr_0</th>\n",
       "      <th>chr_1</th>\n",
       "      <th>...</th>\n",
       "      <th>gamma_theta</th>\n",
       "      <th>gamma_delta</th>\n",
       "      <th>beta_alpha</th>\n",
       "      <th>beta_theta</th>\n",
       "      <th>beta_delta</th>\n",
       "      <th>alpha_theta</th>\n",
       "      <th>alpha_delta</th>\n",
       "      <th>theta_delta</th>\n",
       "      <th>mean_abs_sec_dif</th>\n",
       "      <th>dfa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3590.459896</td>\n",
       "      <td>6675.292969</td>\n",
       "      <td>0.328125</td>\n",
       "      <td>347.159565</td>\n",
       "      <td>57.058810</td>\n",
       "      <td>-24.870341</td>\n",
       "      <td>33.284216</td>\n",
       "      <td>-22.960826</td>\n",
       "      <td>0.527888</td>\n",
       "      <td>0.643746</td>\n",
       "      <td>...</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>1.132221</td>\n",
       "      <td>2.200579</td>\n",
       "      <td>1.193993</td>\n",
       "      <td>1.353591</td>\n",
       "      <td>0.542581</td>\n",
       "      <td>0.615107</td>\n",
       "      <td>1.133667</td>\n",
       "      <td>5.518584</td>\n",
       "      <td>0.822449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3752.577012</td>\n",
       "      <td>6998.291016</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>338.965993</td>\n",
       "      <td>44.552563</td>\n",
       "      <td>-15.600180</td>\n",
       "      <td>22.562177</td>\n",
       "      <td>-20.510662</td>\n",
       "      <td>0.742114</td>\n",
       "      <td>0.796420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.629322</td>\n",
       "      <td>0.510460</td>\n",
       "      <td>2.931911</td>\n",
       "      <td>1.770789</td>\n",
       "      <td>1.436335</td>\n",
       "      <td>0.603971</td>\n",
       "      <td>0.489897</td>\n",
       "      <td>0.811127</td>\n",
       "      <td>5.150809</td>\n",
       "      <td>0.825310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647.662002</td>\n",
       "      <td>7105.957031</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>370.701522</td>\n",
       "      <td>50.350531</td>\n",
       "      <td>-16.855660</td>\n",
       "      <td>16.781457</td>\n",
       "      <td>-21.681031</td>\n",
       "      <td>0.716820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.276071</td>\n",
       "      <td>0.696740</td>\n",
       "      <td>2.227426</td>\n",
       "      <td>2.938295</td>\n",
       "      <td>0.899457</td>\n",
       "      <td>1.319144</td>\n",
       "      <td>0.403810</td>\n",
       "      <td>0.306115</td>\n",
       "      <td>6.430567</td>\n",
       "      <td>0.957758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3649.478683</td>\n",
       "      <td>6901.391602</td>\n",
       "      <td>0.283854</td>\n",
       "      <td>352.184349</td>\n",
       "      <td>43.431659</td>\n",
       "      <td>-21.810604</td>\n",
       "      <td>30.115513</td>\n",
       "      <td>-3.182163</td>\n",
       "      <td>0.758215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.486844</td>\n",
       "      <td>0.570555</td>\n",
       "      <td>2.818923</td>\n",
       "      <td>5.760856</td>\n",
       "      <td>1.321710</td>\n",
       "      <td>2.043637</td>\n",
       "      <td>0.468870</td>\n",
       "      <td>0.229429</td>\n",
       "      <td>5.120279</td>\n",
       "      <td>0.801699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3782.088471</td>\n",
       "      <td>7116.723633</td>\n",
       "      <td>0.302083</td>\n",
       "      <td>351.714564</td>\n",
       "      <td>44.032455</td>\n",
       "      <td>-17.494524</td>\n",
       "      <td>22.250526</td>\n",
       "      <td>-16.676041</td>\n",
       "      <td>0.649750</td>\n",
       "      <td>0.483859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855392</td>\n",
       "      <td>0.937899</td>\n",
       "      <td>2.069664</td>\n",
       "      <td>1.394641</td>\n",
       "      <td>1.529161</td>\n",
       "      <td>0.673849</td>\n",
       "      <td>0.738845</td>\n",
       "      <td>1.096455</td>\n",
       "      <td>5.472301</td>\n",
       "      <td>0.875740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       spc_cnt     spc_roff        zc      mfcc_0     mfcc_1     mfcc_2  \\\n",
       "0  3590.459896  6675.292969  0.328125  347.159565  57.058810 -24.870341   \n",
       "1  3752.577012  6998.291016  0.302083  338.965993  44.552563 -15.600180   \n",
       "2  3647.662002  7105.957031  0.250000  370.701522  50.350531 -16.855660   \n",
       "3  3649.478683  6901.391602  0.283854  352.184349  43.431659 -21.810604   \n",
       "4  3782.088471  7116.723633  0.302083  351.714564  44.032455 -17.494524   \n",
       "\n",
       "      mfcc_3     mfcc_4     chr_0     chr_1  ...  gamma_theta  gamma_delta  \\\n",
       "0  33.284216 -22.960826  0.527888  0.643746  ...     0.998724     1.132221   \n",
       "1  22.562177 -20.510662  0.742114  0.796420  ...     0.629322     0.510460   \n",
       "2  16.781457 -21.681031  0.716820  1.000000  ...     2.276071     0.696740   \n",
       "3  30.115513  -3.182163  0.758215  1.000000  ...     2.486844     0.570555   \n",
       "4  22.250526 -16.676041  0.649750  0.483859  ...     0.855392     0.937899   \n",
       "\n",
       "   beta_alpha  beta_theta  beta_delta  alpha_theta  alpha_delta  theta_delta  \\\n",
       "0    2.200579    1.193993    1.353591     0.542581     0.615107     1.133667   \n",
       "1    2.931911    1.770789    1.436335     0.603971     0.489897     0.811127   \n",
       "2    2.227426    2.938295    0.899457     1.319144     0.403810     0.306115   \n",
       "3    2.818923    5.760856    1.321710     2.043637     0.468870     0.229429   \n",
       "4    2.069664    1.394641    1.529161     0.673849     0.738845     1.096455   \n",
       "\n",
       "   mean_abs_sec_dif       dfa  \n",
       "0          5.518584  0.822449  \n",
       "1          5.150809  0.825310  \n",
       "2          6.430567  0.957758  \n",
       "3          5.120279  0.801699  \n",
       "4          5.472301  0.875740  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.flatten()\n",
    "y_p = pd.Series(y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

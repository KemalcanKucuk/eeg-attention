{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "#from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import linregress, skew, kurtosis\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.signal import detrend\n",
    "from nolds import dfa\n",
    "import utils, training, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_loader(path=constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "\n",
    "subject_idx = {1: [0, 187],\n",
    "               2: [188, 319],\n",
    "               3: [320, 470],\n",
    "               4: [471, 617],\n",
    "               5: [618, 841],\n",
    "               6: [842, 1007],\n",
    "               7: [1008, 1109],\n",
    "               8: [1110, 1373],\n",
    "               9: [1374, 1687],\n",
    "               10: [1688, 1795],\n",
    "               11: [1796, 2021]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "model_dfs = []\n",
    "for model in tqdm(constants.ALL_MODELS):\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subjects\"] == sub].drop('subjects', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        one_out_results[sub] = training.model_training(data, model, stats=False, cm=False)\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = SVC()\n",
    "for model in [\"SVM-def\"]:\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subject\"] == sub].drop('subject', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        test_model.fit(X_train, y_train)\n",
    "        stats_dict = {}\n",
    "\n",
    "        stats_dict['training_acc'] = test_model.score(X_train, y_train)\n",
    "        stats_dict['test_acc'] = test_model.score(X_test, y_test)\n",
    "\n",
    "        stats_dict['sensitivity'] = recall_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['precision'] = precision_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['f1'] = f1_score(y_test, test_model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, test_model.predict(X_test))\n",
    "        stats_dict['auc'] = roc_auc_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['logloss'] = log_loss(y_test, test_model.predict(X_test))\n",
    "        one_out_results[sub] = stats_dict\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

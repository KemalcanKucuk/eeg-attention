{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "#from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import linregress, skew, kurtosis\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.signal import detrend\n",
    "from nolds import dfa\n",
    "import utils, training, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.data_loader(path=constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.SELECTED_CHANNELS)\n",
    "\n",
    "subject_idx = {1: [0, 187],\n",
    "               2: [188, 319],\n",
    "               3: [320, 470],\n",
    "               4: [471, 617],\n",
    "               5: [618, 841],\n",
    "               6: [842, 1007],\n",
    "               7: [1008, 1109],\n",
    "               8: [1110, 1373],\n",
    "               9: [1374, 1687],\n",
    "               10: [1688, 1795],\n",
    "               11: [1796, 2021]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:29<00:00, 149.02s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model_dfs = []\n",
    "for model in tqdm(['SVM']):\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subjects\"] == sub].drop('subjects', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        one_out_results[sub] = training.model_training(data, model, stats=False, cm=False)\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "test_model = SVC()\n",
    "for model in [\"SVM-def\"]:\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subjects\"] == sub].drop('subjects', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        test_model.fit(X_train, y_train)\n",
    "        stats_dict = {}\n",
    "\n",
    "        stats_dict['training_acc'] = test_model.score(X_train, y_train)\n",
    "        stats_dict['test_acc'] = test_model.score(X_test, y_test)\n",
    "\n",
    "        stats_dict['sensitivity'] = recall_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['precision'] = precision_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['f1'] = f1_score(y_test, test_model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, test_model.predict(X_test))\n",
    "        stats_dict['auc'] = roc_auc_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['logloss'] = log_loss(y_test, test_model.predict(X_test))\n",
    "        one_out_results[sub] = stats_dict\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "test_model = MLPClassifier()\n",
    "for model in [\"NN-def\"]:\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subjects\"] == sub].drop('subjects', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subjects', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        test_model.fit(X_train, y_train)\n",
    "        stats_dict = {}\n",
    "\n",
    "        stats_dict['training_acc'] = test_model.score(X_train, y_train)\n",
    "        stats_dict['test_acc'] = test_model.score(X_test, y_test)\n",
    "\n",
    "        stats_dict['sensitivity'] = recall_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['precision'] = precision_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['f1'] = f1_score(y_test, test_model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, test_model.predict(X_test))\n",
    "        stats_dict['auc'] = roc_auc_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['logloss'] = log_loss(y_test, test_model.predict(X_test))\n",
    "        one_out_results[sub] = stats_dict\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import sklearn as sk\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import (ConfusionMatrixDisplay, accuracy_score,\n",
    "                             classification_report, confusion_matrix, f1_score,\n",
    "                             log_loss, precision_score, recall_score,\n",
    "                             roc_auc_score, roc_curve)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

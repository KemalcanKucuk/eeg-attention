{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "#from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import linregress, skew, kurtosis\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.signal import detrend\n",
    "from nolds import dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from training import *\n",
    "dataset = data_loader(\"leaveout.csv\")\n",
    "# the label column should be the last one, we swap it with the subject\n",
    "new_cols = ['channels', 'spc_cnt', 'spc_roff', 'zc', 'mfcc_0', 'mfcc_1', 'mfcc_2',\n",
    "       'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9',\n",
    "       'chr_0', 'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7',\n",
    "       'chr_8', 'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14',\n",
    "       'chr_15', 'chr_16', 'chr_17', 'chr_18', 'chr_19', 'mel_0', 'mel_1',\n",
    "       'mel_2', 'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9',\n",
    "       'mel_10', 'mel_11', 'mel_12', 'mel_13', 'mel_14', 'delta_power',\n",
    "       'theta_power', 'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta',\n",
    "       'gamma_alpha', 'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta',\n",
    "       'beta_delta', 'alpha_theta', 'alpha_delta', 'theta_delta',\n",
    "       'mean_abs_sec_dif', 'dfa', 'slope', 'skew', 'kurtosis', 'activity',\n",
    "       'mobility', 'complexity', 'rms', 'tempo', 'ton_0', 'ton_1', 'ton_2',\n",
    "       'ton_3', 'ton_4', 'ton_5', 'subject', 'label']\n",
    "\n",
    "dataset = dataset.reindex(columns=new_cols) # this is fixed in the extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_idx = {1: [0, 187],\n",
    "               2: [188, 319],\n",
    "               3: [320, 470],\n",
    "               4: [471, 617],\n",
    "               5: [618, 841],\n",
    "               6: [842, 1007],\n",
    "               7: [1008, 1109],\n",
    "               8: [1110, 1373],\n",
    "               9: [1374, 1687],\n",
    "               10: [1688, 1795],\n",
    "               11: [1796, 2021]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channels = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "reduced_dataset = channel_selection(dataset, selected_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [28:47<00:00, 172.75s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'Logistic Regression', 'NN', 'GBC']\n",
    "model_dfs = []\n",
    "for model in tqdm(models):\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subject\"] == sub].drop('subject', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        one_out_results[sub] = model_training(data, model, stats=False, cm=False)\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = SVC()\n",
    "for model in [\"SVM-def\"]:\n",
    "    one_out_results = {}\n",
    "    for sub in subject_idx:\n",
    "        one_out = reduced_dataset[reduced_dataset[\"subject\"] == sub].drop('subject', axis=1)\n",
    "        X_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1).drop('label', axis=1)\n",
    "        y_train = (reduced_dataset.drop(one_out.index)).drop('subject', axis=1)['label']\n",
    "        X_test = one_out.drop('label', axis=1)\n",
    "        y_test = one_out['label']\n",
    "        data = [X_train, X_test, y_train, y_test]\n",
    "        test_model.fit(X_train, y_train)\n",
    "        stats_dict = {}\n",
    "\n",
    "        stats_dict['training_acc'] = test_model.score(X_train, y_train)\n",
    "        stats_dict['test_acc'] = test_model.score(X_test, y_test)\n",
    "\n",
    "        stats_dict['sensitivity'] = recall_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['precision'] = precision_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['f1'] = f1_score(y_test, test_model.predict(X_test))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, test_model.predict(X_test))\n",
    "        stats_dict['auc'] = roc_auc_score(y_test, test_model.predict(X_test))\n",
    "        stats_dict['logloss'] = log_loss(y_test, test_model.predict(X_test))\n",
    "        one_out_results[sub] = stats_dict\n",
    "        one_out_results_df = pd.DataFrame.from_dict(one_out_results).T\n",
    "        one_out_results_df.to_csv(\"outs/\" + model + \"_one_out.csv\")\n",
    "        model_dfs.append(one_out_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

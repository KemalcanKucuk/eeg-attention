{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils, training, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the channels to be processed\n",
    "dataset = utils.data_loader(path = constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.ALL_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Channel Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/paws/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "#all_channels_perf = pd.DataFrame(columns=all_channels)\n",
    "#all_channels_perf = dict.fromkeys(all_channels, None)\n",
    "all_channels_perf = {}\n",
    "\n",
    "import time, tqdm\n",
    "start = time.time()\n",
    "\n",
    "for channel in tqdm.tqdm(constants.ALL_CHANNELS):\n",
    "    reduced_dataset = utils.channel_selection(dataset, [channel])\n",
    "    data = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "    for model in constants.ALL_MODELS:\n",
    "        all_channels_perf[channel + '-' + model] = training.model_training(data, model, stats=False)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_perf_df = pd.DataFrame.from_dict(all_channels_perf)\n",
    "all_channels_perf_df.to_csv('indv_channel_perfs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.data_loader(path = constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.ALL_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "\n",
    "feature_subsets['stat_features'] = ['skew', 'kurtosis', 'rms', 'dfa', 'mean_abs_sec_dif', 'zc']\n",
    "feature_subsets['hjorth_features'] = ['activity', 'mobility', 'complexity']\n",
    "feature_subsets['time_features'] = feature_subsets['stat_features'] + feature_subsets['hjorth_features']\n",
    "\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['spectral_features'] = ['spc_cnt', 'spc_roff', 'slope', 'mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9', 'mel_0', 'mel_1', 'mel_2', 'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10', 'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['freq_features'] = feature_subsets['bands'] + feature_subsets['spectral_features']\n",
    "\n",
    "#feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3', 'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "#feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2', 'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10', 'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "#feature_subsets['chr_features'] = ['chr_0', 'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8', 'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15', 'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "\n",
    "#feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "#feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features'] + feature_subsets['freq_features']\n",
    "\n",
    "#feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "#feature_subsets['coeffs'] = feature_subsets['spectral_features'] # + feature_subsets['music']\n",
    "\n",
    "#feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "#feature_subsets['no_music'] = feature_subsets['spectral_features'] + feature_subsets['comb_domain']\n",
    "\n",
    "#feature_subsets['all'] = feature_subsets['coeffs'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.6833992746455655\n",
      "Test Accuracy:  0.6780415430267063\n",
      "Sensitivity (Recall): 0.6552402821059538\n",
      "Precision: 0.688911881358855\n",
      "F1_score: 0.6716543375924681\n",
      "AUC: 0.6781586663222396\n",
      "Logloss: 11.60455902884039\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.650016485328058\n",
      "Test Accuracy:  0.6423508077810749\n",
      "Sensitivity (Recall): 0.5942266688535345\n",
      "Precision: 0.660167638483965\n",
      "F1_score: 0.6254639620198532\n",
      "AUC: 0.6425980071691036\n",
      "Logloss: 12.890983519236672\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7000700626442466\n",
      "Test Accuracy:  0.6863666336960106\n",
      "Sensitivity (Recall): 0.618008856814827\n",
      "Precision: 0.7185354691075515\n",
      "F1_score: 0.6644916674014638\n",
      "AUC: 0.6867177672640828\n",
      "Logloss: 11.304492346323011\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.6563427299703264\n",
      "Test Accuracy:  0.647131552917903\n",
      "Sensitivity (Recall): 0.6281777923568969\n",
      "Precision: 0.6553730321697467\n",
      "F1_score: 0.6414873126203836\n",
      "AUC: 0.6472289127484567\n",
      "Logloss: 12.718667998583129\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.710435212660732\n",
      "Test Accuracy:  0.7011210023079459\n",
      "Sensitivity (Recall): 0.6470395276365426\n",
      "Precision: 0.7279940948514486\n",
      "F1_score: 0.6851337269885378\n",
      "AUC: 0.7013988027577907\n",
      "Logloss: 10.77269099809914\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7133407517309595\n",
      "Test Accuracy:  0.7025222551928784\n",
      "Sensitivity (Recall): 0.6427751353124488\n",
      "Precision: 0.7325233644859813\n",
      "F1_score: 0.6847208875687953\n",
      "AUC: 0.7028291583770196\n",
      "Logloss: 10.722184724804137\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  0.9241880975931421\n",
      "Test Accuracy:  0.6967523903725684\n",
      "Sensitivity (Recall): 0.7064129899950795\n",
      "Precision: 0.6951258876694641\n",
      "F1_score: 0.7007239892621817\n",
      "AUC: 0.6967027667456757\n",
      "Logloss: 10.930151732489449\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  0.8911968348170128\n",
      "Test Accuracy:  0.683151994724695\n",
      "Sensitivity (Recall): 0.6824667869443989\n",
      "Precision: 0.6856154226396441\n",
      "F1_score: 0.684037481505836\n",
      "AUC: 0.6831555144332598\n",
      "Logloss: 11.420359679176254\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  0.9589927464556545\n",
      "Test Accuracy:  0.7255192878338279\n",
      "Sensitivity (Recall): 0.7155978350008201\n",
      "Precision: 0.7321698271522068\n",
      "F1_score: 0.7237889847378898\n",
      "AUC: 0.725570251386077\n",
      "Logloss: 9.89328765131554\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  0.971789482360699\n",
      "Test Accuracy:  0.7031816683151995\n",
      "Sensitivity (Recall): 0.6775463342627521\n",
      "Precision: 0.7164412070759626\n",
      "F1_score: 0.6964511506364326\n",
      "AUC: 0.7033133494014671\n",
      "Logloss: 10.698417066782959\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  0.9998557533794923\n",
      "Test Accuracy:  0.8063798219584569\n",
      "Sensitivity (Recall): 0.7872724290634738\n",
      "Precision: 0.8202323991797676\n",
      "F1_score: 0.8034145116746171\n",
      "AUC: 0.8064779709526152\n",
      "Logloss: 6.978778586468528\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8271513353115727\n",
      "Sensitivity (Recall): 0.8072822699688371\n",
      "Precision: 0.8422313483915127\n",
      "F1_score: 0.8243865672891717\n",
      "AUC: 0.8272533967905494\n",
      "Logloss: 6.230097358801407\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_results = {}\n",
    "for model in ['K-NN', 'GBC']:\n",
    "    for k in feature_subsets:\n",
    "        data = training.data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = training.model_training(data, model, stats=True, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('outs/{}_latest_feature_perf.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "reduced_dataset1 = channel_selection(dataset, [\"Cz\",\"CP3\",\"CPz\",\"P3\", 'O1'])\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset1, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('{}_feature_perfO1.csv'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "results_dict = {}\n",
    "for model in tqdm(constants.ALL_MODELS):\n",
    "    model_results = training.model_training(data = [X_train, X_test, y_train, y_test], model_family=model)\n",
    "    t_stat, p_value = stats.ttest_ind(model_results['predictions'], y_test)\n",
    "    results_dict[model + '_t'] = t_stat\n",
    "    results_dict[model + '_pval'] = p_value\n",
    "results_df = pd.DataFrame.from_dict(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K-NN_t': array([-10.55984707]),\n",
       " 'K-NN_pval': array([5.20917787e-26]),\n",
       " 'K-NN1_t': array([-3.21081517]),\n",
       " 'K-NN1_pval': array([0.00132531]),\n",
       " 'K-NN2_t': array([-16.55796351]),\n",
       " 'K-NN2_pval': array([3.04255371e-61]),\n",
       " 'K-NN3_t': array([-5.8102629]),\n",
       " 'K-NN3_pval': array([6.31543069e-09]),\n",
       " 'SVM_t': array([-3.22366805]),\n",
       " 'SVM_pval': array([0.00126727]),\n",
       " 'DTC_t': array([0.17974952]),\n",
       " 'DTC_pval': array([0.85735071]),\n",
       " 'RFC_t': array([-3.91791683]),\n",
       " 'RFC_pval': array([8.95622585e-05]),\n",
       " 'Logistic Regression_t': array([-1.83614421]),\n",
       " 'Logistic Regression_pval': array([0.06634856]),\n",
       " 'NN_t': array([-1.14270379]),\n",
       " 'NN_pval': array([0.25317287]),\n",
       " 'GBC_t': array([-3.21081517]),\n",
       " 'GBC_pval': array([0.00132531])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

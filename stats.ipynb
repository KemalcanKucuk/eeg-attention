{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Channel Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the channels to be processed\n",
    "all_channels =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'Logistic Regression', 'NN', 'GBC']\n",
    "dataset = data_loader(path = csv_file)\n",
    "#reduced_dataset = channel_selection(dataset, all_channels)\n",
    "#all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [13:06<00:00, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.0755877494812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#all_channels_perf = pd.DataFrame(columns=all_channels)\n",
    "#all_channels_perf = dict.fromkeys(all_channels, None)\n",
    "all_channels_perf = {}\n",
    "\n",
    "import time, tqdm\n",
    "start = time.time()\n",
    "\n",
    "for channel in tqdm.tqdm(all_channels):\n",
    "    reduced_dataset = channel_selection(dataset, [channel])\n",
    "    all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]\n",
    "    data = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "    for model in models:\n",
    "        all_channels_perf[channel + '-' + model] = model_training(data, model, stats=False)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_perf_df = pd.DataFrame.from_dict(all_channels_perf)\n",
    "all_channels_perf_df.to_csv('indv_channel_perfs.csv')\n",
    "\n",
    "#df = all_channels_perf_df\n",
    "#sorted_df = df.sort_values(df.last_valid_index(), axis=1)\n",
    "#sorted_df.to_csv('sorted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'Logistic Regression', 'NN', 'GBC']\n",
    "dataset = data_loader(path = csv_file)\n",
    "\n",
    "selected_channels = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "reduced_dataset = channel_selection(dataset, selected_channels)\n",
    "all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['time_features'] = ['skew', 'kurtosis', 'rms', 'activity', 'mobility', 'complexity', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['freq_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
    "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2',\n",
    "               'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10',\n",
    "               'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['chr_features'] = ['chr_0',\n",
    "                'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8',\n",
    "                'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15',\n",
    "                'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "feature_subsets['coeffs'] = feature_subsets['spectral_features'] + feature_subsets['music']\n",
    "\n",
    "feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "feature_subsets['all'] = feature_subsets['coeffs'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Feature Subset: bands -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.7723338485316847\n",
      "Test Accuracy:  0.7466007416563659\n",
      "Sensitivity (Recall): 0.7354037267080745\n",
      "Precision: 0.7503168567807351\n",
      "F1_score: 0.7427854454203262\n",
      "AUC: 0.7465456517919216\n",
      "Logloss: 9.1334350367973\n",
      "\n",
      "-------Feature Subset: time_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.7871715610510046\n",
      "Test Accuracy:  0.776885043263288\n",
      "Sensitivity (Recall): 0.7937888198757764\n",
      "Precision: 0.7661870503597122\n",
      "F1_score: 0.7797437461866993\n",
      "AUC: 0.7769682106758956\n",
      "Logloss: 8.041878166545915\n",
      "\n",
      "-------Feature Subset: freq_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.676661514683153\n",
      "Test Accuracy:  0.6779975278121138\n",
      "Sensitivity (Recall): 0.639751552795031\n",
      "Precision: 0.6903485254691689\n",
      "F1_score: 0.6640876853642812\n",
      "AUC: 0.6778093557333089\n",
      "Logloss: 11.606145497979009\n",
      "\n",
      "-------Feature Subset: mfcc_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.8545595054095827\n",
      "Test Accuracy:  0.796044499381953\n",
      "Sensitivity (Recall): 0.7950310559006211\n",
      "Precision: 0.7950310559006211\n",
      "F1_score: 0.7950310559006211\n",
      "AUC: 0.7960395131901629\n",
      "Logloss: 7.351301371080754\n",
      "\n",
      "-------Feature Subset: mel_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9210200927357033\n",
      "Test Accuracy:  0.7991347342398022\n",
      "Sensitivity (Recall): 0.7975155279503106\n",
      "Precision: 0.7985074626865671\n",
      "F1_score: 0.798011187072716\n",
      "AUC: 0.7991267676651922\n",
      "Logloss: 7.23991801697347\n",
      "\n",
      "-------Feature Subset: chr_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9880989180834622\n",
      "Test Accuracy:  0.7731767614338689\n",
      "Sensitivity (Recall): 0.7677018633540372\n",
      "Precision: 0.7744360902255639\n",
      "F1_score: 0.7710542732376793\n",
      "AUC: 0.7731498246659485\n",
      "Logloss: 8.175538191474656\n",
      "\n",
      "-------Feature Subset: ton_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.6200927357032457\n",
      "Test Accuracy:  0.5618046971569839\n",
      "Sensitivity (Recall): 0.4062111801242236\n",
      "Precision: 0.5860215053763441\n",
      "F1_score: 0.47982391782831996\n",
      "AUC: 0.5610391693979052\n",
      "Logloss: 15.794159612412892\n",
      "\n",
      "-------Feature Subset: spectral_features -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9996908809891808\n",
      "Test Accuracy:  0.907292954264524\n",
      "Sensitivity (Recall): 0.9204968944099379\n",
      "Precision: 0.8960096735187424\n",
      "F1_score: 0.9080882352941176\n",
      "AUC: 0.9073579182996798\n",
      "Logloss: 3.3415006232185247\n",
      "\n",
      "-------Feature Subset: music -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8467243510506799\n",
      "Sensitivity (Recall): 0.8459627329192546\n",
      "Precision: 0.8459627329192546\n",
      "F1_score: 0.8459627329192546\n",
      "AUC: 0.8467206038520013\n",
      "Logloss: 5.524614363721294\n",
      "\n",
      "-------Feature Subset: coeffs -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9468479604449939\n",
      "Sensitivity (Recall): 0.9664596273291925\n",
      "Precision: 0.929510155316607\n",
      "F1_score: 0.9476248477466505\n",
      "AUC: 0.9469444508109678\n",
      "Logloss: 1.9157936906452875\n",
      "\n",
      "-------Feature Subset: comb_domain -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9123647604327666\n",
      "Test Accuracy:  0.8294190358467244\n",
      "Sensitivity (Recall): 0.8422360248447205\n",
      "Precision: 0.8198307134220073\n",
      "F1_score: 0.8308823529411765\n",
      "AUC: 0.8294820960631967\n",
      "Logloss: 6.1483611467220864\n",
      "\n",
      "-------Feature Subset: all -------\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9375772558714462\n",
      "Sensitivity (Recall): 0.9751552795031055\n",
      "Precision: 0.9064665127020786\n",
      "F1_score: 0.9395571514063434\n",
      "AUC: 0.9377621415965712\n",
      "Logloss: 2.2499437529671398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in feature_subsets:\n",
    "    print(\"-------Feature Subset: {} -------\".format(k))\n",
    "    data = data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "    model_training(data, 'SVM', stats=True, cm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('outs/{}_feature_perf.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "reduced_dataset1 = channel_selection(dataset, [\"Cz\",\"CP3\",\"CPz\",\"P3\", 'O1'])\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset1, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('{}_feature_perfO1.csv'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Denemesi, sonra training.py'a eklenecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7474497681607419\n",
      "Test Accuracy:  0.7323856613102596\n",
      "Sensitivity (Recall): 0.6832298136645962\n",
      "Precision: 0.7554945054945055\n",
      "F1_score: 0.7175472928897586\n",
      "AUC: 0.732143812121351\n",
      "Logloss: 9.645798465690806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'NN', 'GBC', 'Logistic Regression']\n",
    "dataset = data_loader(path = csv_file)\n",
    "selected_channels = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "reduced_dataset = channel_selection(dataset, selected_channels)\n",
    "all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]\n",
    "data = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "model_training(data, 'K-NN', stats=True, cm=False)\n",
    "\n",
    "test_model = KNeighborsClassifier(leaf_size= 10, n_neighbors= int(np.sqrt(np.prod(data[0].shape))), p= 1)\n",
    "X = utils.feature_selection(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "labels = reduced_dataset.iloc[:, -1:]\n",
    "y = labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=10, n_neighbors=714, p=1): 0.7185924735103615\n",
      "SVC(): 0.7413451637537811\n",
      "K-NN1: 0.9240867849555825\n",
      "K-NN2: 0.8596640454136482\n",
      "K-NN3: 0.872281529759898\n",
      "SVM: 0.5346212560763153\n",
      "DTC: 0.7601396014074806\n",
      "RFC: 0.8478022066226198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7486409464336359\n",
      "NN: 0.500123609394314\n",
      "GBC: 0.8794537030454389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "cv_results = pd.DataFrame()\n",
    "\n",
    "model = KNeighborsClassifier(leaf_size= 10, n_neighbors= int(np.sqrt(np.prod(data[0].shape))), p= 1)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_results[model] = np.mean(scores)\n",
    "print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "\n",
    "model = SVC()\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_results[model] = np.mean(scores)\n",
    "print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "\n",
    "for model in models[1:len(models)]:\n",
    "    scores = cross_val_score(model_switch(model), X, y, cv=5)\n",
    "    print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "    cv_results[model] = np.mean(scores)\n",
    "\n",
    "cv_results.to_csv('outs/cross_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

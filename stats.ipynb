{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import utils, training, constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the channels to be processed\n",
    "dataset = utils.data_loader(path = constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.ALL_CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Channel Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/kemalcankucuk/Documents/PAWS Work/eeg-attention/paws/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:698: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "#all_channels_perf = pd.DataFrame(columns=all_channels)\n",
    "#all_channels_perf = dict.fromkeys(all_channels, None)\n",
    "all_channels_perf = {}\n",
    "\n",
    "import time, tqdm\n",
    "start = time.time()\n",
    "\n",
    "for channel in tqdm.tqdm(constants.ALL_CHANNELS):\n",
    "    reduced_dataset = utils.channel_selection(dataset, [channel])\n",
    "    data = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)\n",
    "    for model in constants.ALL_MODELS:\n",
    "        all_channels_perf[channel + '-' + model] = training.model_training(data, model, stats=False)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_perf_df = pd.DataFrame.from_dict(all_channels_perf)\n",
    "all_channels_perf_df.to_csv('indv_channel_perfs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = utils.data_loader(path = constants.MAIN_CSV_FILE)\n",
    "reduced_dataset = utils.channel_selection(dataset, constants.ALL_CHANNELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['time_features'] = ['skew', 'kurtosis', 'rms', 'activity', 'mobility', 'complexity', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['freq_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
    "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2',\n",
    "               'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10',\n",
    "               'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['chr_features'] = ['chr_0',\n",
    "                'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8',\n",
    "                'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15',\n",
    "                'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "feature_subsets['coeffs'] = feature_subsets['spectral_features'] + feature_subsets['music']\n",
    "\n",
    "feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "feature_subsets['no_music'] = feature_subsets['spectral_features'] + feature_subsets['comb_domain']\n",
    "\n",
    "feature_subsets['all'] = feature_subsets['coeffs'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in feature_subsets:\n",
    "    print(\"-------Feature Subset: {} -------\".format(k))\n",
    "    data = training.data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "    for model in constants.ALL_MODELS:\n",
    "        training.model_training(data, model, stats=True, cm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = training.data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = training.model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('outs/{}_feature_perf.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "reduced_dataset1 = channel_selection(dataset, [\"Cz\",\"CP3\",\"CPz\",\"P3\", 'O1'])\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset1, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('{}_feature_perfO1.csv'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = training.data_preparation(dataset=reduced_dataset, feature_subset=constants.ALL_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "results_dict = {}\n",
    "for model in tqdm(constants.ALL_MODELS):\n",
    "    model_results = training.model_training(data = [X_train, X_test, y_train, y_test], model_family=model)\n",
    "    t_stat, p_value = stats.ttest_ind(model_results['predictions'], y_test)\n",
    "    results_dict[model + '_t'] = t_stat\n",
    "    results_dict[model + '_pval'] = p_value\n",
    "results_df = pd.DataFrame.from_dict(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'K-NN_t': array([-10.55984707]),\n",
       " 'K-NN_pval': array([5.20917787e-26]),\n",
       " 'K-NN1_t': array([-3.21081517]),\n",
       " 'K-NN1_pval': array([0.00132531]),\n",
       " 'K-NN2_t': array([-16.55796351]),\n",
       " 'K-NN2_pval': array([3.04255371e-61]),\n",
       " 'K-NN3_t': array([-5.8102629]),\n",
       " 'K-NN3_pval': array([6.31543069e-09]),\n",
       " 'SVM_t': array([-3.22366805]),\n",
       " 'SVM_pval': array([0.00126727]),\n",
       " 'DTC_t': array([0.17974952]),\n",
       " 'DTC_pval': array([0.85735071]),\n",
       " 'RFC_t': array([-3.91791683]),\n",
       " 'RFC_pval': array([8.95622585e-05]),\n",
       " 'Logistic Regression_t': array([-1.83614421]),\n",
       " 'Logistic Regression_pval': array([0.06634856]),\n",
       " 'NN_t': array([-1.14270379]),\n",
       " 'NN_pval': array([0.25317287]),\n",
       " 'GBC_t': array([-3.21081517]),\n",
       " 'GBC_pval': array([0.00132531])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

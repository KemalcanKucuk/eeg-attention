{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from training import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Channel Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the channels to be processed\n",
    "all_channels =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'Logistic Regression', 'NN', 'GBC']\n",
    "dataset = data_loader(path = csv_file)\n",
    "#reduced_dataset = channel_selection(dataset, all_channels)\n",
    "#all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [13:06<00:00, 26.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "786.0755877494812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#all_channels_perf = pd.DataFrame(columns=all_channels)\n",
    "#all_channels_perf = dict.fromkeys(all_channels, None)\n",
    "all_channels_perf = {}\n",
    "\n",
    "import time, tqdm\n",
    "start = time.time()\n",
    "\n",
    "for channel in tqdm.tqdm(all_channels):\n",
    "    reduced_dataset = channel_selection(dataset, [channel])\n",
    "    all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]\n",
    "    data = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "    for model in models:\n",
    "        all_channels_perf[channel + '-' + model] = model_training(data, model, stats=False)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels_perf_df = pd.DataFrame.from_dict(all_channels_perf)\n",
    "all_channels_perf_df.to_csv('indv_channel_perfs.csv')\n",
    "\n",
    "#df = all_channels_perf_df\n",
    "#sorted_df = df.sort_values(df.last_valid_index(), axis=1)\n",
    "#sorted_df.to_csv('sorted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'Logistic Regression', 'NN', 'GBC']\n",
    "dataset = data_loader(path = csv_file)\n",
    "\n",
    "selected_channels = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "reduced_dataset = channel_selection(dataset, selected_channels)\n",
    "all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_subsets = {}\n",
    "feature_subsets['bands'] = ['delta_power', 'theta_power',\n",
    "       'alpha_power', 'beta_power', 'gamma_power', 'gamma_beta', 'gamma_alpha',\n",
    "       'gamma_theta', 'gamma_delta', 'beta_alpha', 'beta_theta', 'beta_delta',\n",
    "       'alpha_theta', 'alpha_delta', 'theta_delta']\n",
    "\n",
    "feature_subsets['time_features'] = ['skew', 'kurtosis', 'rms', 'activity', 'mobility', 'complexity', 'dfa', 'mean_abs_sec_dif']\n",
    "\n",
    "feature_subsets['freq_features'] = ['spc_cnt', 'spc_roff', 'zc', 'slope']\n",
    "\n",
    "feature_subsets['mfcc_features'] = ['mfcc_0', 'mfcc_1', 'mfcc_2', 'mfcc_3',\n",
    "       'mfcc_4', 'mfcc_5', 'mfcc_6', 'mfcc_7', 'mfcc_8', 'mfcc_9']\n",
    "\n",
    "feature_subsets['mel_features'] = ['mel_0', 'mel_1', 'mel_2',\n",
    "               'mel_3', 'mel_4', 'mel_5', 'mel_6', 'mel_7', 'mel_8', 'mel_9', 'mel_10',\n",
    "               'mel_11', 'mel_12', 'mel_13', 'mel_14']\n",
    "\n",
    "feature_subsets['chr_features'] = ['chr_0',\n",
    "                'chr_1', 'chr_2', 'chr_3', 'chr_4', 'chr_5', 'chr_6', 'chr_7', 'chr_8',\n",
    "                'chr_9', 'chr_10', 'chr_11', 'chr_12', 'chr_13', 'chr_14', 'chr_15',\n",
    "                'chr_16', 'chr_17', 'chr_18', 'chr_19']\n",
    "\n",
    "feature_subsets['ton_features'] = ['ton_0', 'ton_1', 'ton_2', 'ton_3', 'ton_4', 'ton_5']\n",
    "\n",
    "feature_subsets['spectral_features'] = feature_subsets['mfcc_features'] + feature_subsets['mel_features']\n",
    "\n",
    "feature_subsets['music'] = feature_subsets['chr_features'] + feature_subsets['ton_features']\n",
    "\n",
    "feature_subsets['coeffs'] = feature_subsets['spectral_features'] + feature_subsets['music']\n",
    "\n",
    "feature_subsets['comb_domain'] = feature_subsets['time_features'] + feature_subsets['freq_features'] + feature_subsets['bands']\n",
    "\n",
    "feature_subsets['no_music'] = feature_subsets['spectral_features'] + feature_subsets['comb_domain']\n",
    "\n",
    "feature_subsets['all'] = feature_subsets['coeffs'] + feature_subsets['comb_domain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Feature Subset: bands -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7242658423493045\n",
      "Test Accuracy:  0.7175525339925835\n",
      "Sensitivity (Recall): 0.6645962732919255\n",
      "Precision: 0.7409972299168975\n",
      "F1_score: 0.7007203667321545\n",
      "AUC: 0.7172919865844621\n",
      "Logloss: 10.18043856540577\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7163164400494437\n",
      "Sensitivity (Recall): 0.7490683229813665\n",
      "Precision: 0.7011627906976744\n",
      "F1_score: 0.7243243243243244\n",
      "AUC: 0.7164775809248776\n",
      "Logloss: 10.224991907048684\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.8571870170015456\n",
      "Test Accuracy:  0.69221260815822\n",
      "Sensitivity (Recall): 0.537888198757764\n",
      "Precision: 0.774597495527728\n",
      "F1_score: 0.6348973607038123\n",
      "AUC: 0.691453324471133\n",
      "Logloss: 11.093782069085503\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.8601236476043277\n",
      "Test Accuracy:  0.7194066749072929\n",
      "Sensitivity (Recall): 0.7416149068322981\n",
      "Precision: 0.708185053380783\n",
      "F1_score: 0.7245145631067961\n",
      "AUC: 0.7195159405010199\n",
      "Logloss: 10.113608552941402\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.7723338485316847\n",
      "Test Accuracy:  0.7466007416563659\n",
      "Sensitivity (Recall): 0.7354037267080745\n",
      "Precision: 0.7503168567807351\n",
      "F1_score: 0.7427854454203262\n",
      "AUC: 0.7465456517919216\n",
      "Logloss: 9.1334350367973\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7690880989180835\n",
      "Test Accuracy:  0.7169344870210136\n",
      "Sensitivity (Recall): 0.6894409937888198\n",
      "Precision: 0.727391874180865\n",
      "F1_score: 0.7079081632653061\n",
      "AUC: 0.7167992176816179\n",
      "Logloss: 10.20271523622723\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7564894932014833\n",
      "Sensitivity (Recall): 0.760248447204969\n",
      "Precision: 0.7527675276752768\n",
      "F1_score: 0.7564894932014833\n",
      "AUC: 0.7565079874401228\n",
      "Logloss: 8.777008303653991\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.721483771251932\n",
      "Test Accuracy:  0.715698393077874\n",
      "Sensitivity (Recall): 0.662111801242236\n",
      "Precision: 0.739251040221914\n",
      "F1_score: 0.6985583224115334\n",
      "AUC: 0.7154347444095559\n",
      "Logloss: 10.247268577870143\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.7680061823802163\n",
      "Test Accuracy:  0.7453646477132262\n",
      "Sensitivity (Recall): 0.7304347826086957\n",
      "Precision: 0.7509578544061303\n",
      "F1_score: 0.7405541561712846\n",
      "AUC: 0.7452911920423553\n",
      "Logloss: 9.177988378440213\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7478368355995055\n",
      "Sensitivity (Recall): 0.7577639751552795\n",
      "Precision: 0.741190765492102\n",
      "F1_score: 0.7493857493857494\n",
      "AUC: 0.7478856776145401\n",
      "Logloss: 9.088881695154386\n",
      "\n",
      "-------Feature Subset: time_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7372488408037094\n",
      "Test Accuracy:  0.7311495673671199\n",
      "Sensitivity (Recall): 0.7751552795031056\n",
      "Precision: 0.7107061503416856\n",
      "F1_score: 0.7415329768270945\n",
      "AUC: 0.7313660776359316\n",
      "Logloss: 9.690351807333721\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7435105067985167\n",
      "Sensitivity (Recall): 0.7503105590062111\n",
      "Precision: 0.7383863080684596\n",
      "F1_score: 0.7443006777572396\n",
      "AUC: 0.7435439633899444\n",
      "Logloss: 9.244818390904586\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.8709428129829985\n",
      "Test Accuracy:  0.7163164400494437\n",
      "Sensitivity (Recall): 0.5677018633540373\n",
      "Precision: 0.8045774647887324\n",
      "F1_score: 0.6656955571740714\n",
      "AUC: 0.7155852490201919\n",
      "Logloss: 10.224991907048684\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.8768160741885626\n",
      "Test Accuracy:  0.7527812113720643\n",
      "Sensitivity (Recall): 0.7552795031055901\n",
      "Precision: 0.749691738594328\n",
      "F1_score: 0.7524752475247525\n",
      "AUC: 0.7527935030903105\n",
      "Logloss: 8.910668328582732\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.7871715610510046\n",
      "Test Accuracy:  0.776885043263288\n",
      "Sensitivity (Recall): 0.7937888198757764\n",
      "Precision: 0.7661870503597122\n",
      "F1_score: 0.7797437461866993\n",
      "AUC: 0.7769682106758956\n",
      "Logloss: 8.041878166545915\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7948995363214838\n",
      "Test Accuracy:  0.7447466007416563\n",
      "Sensitivity (Recall): 0.8186335403726708\n",
      "Precision: 0.7116630669546437\n",
      "F1_score: 0.7614095898324668\n",
      "AUC: 0.7451101281199147\n",
      "Logloss: 9.200265049261672\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7781211372064277\n",
      "Sensitivity (Recall): 0.7975155279503106\n",
      "Precision: 0.766109785202864\n",
      "F1_score: 0.7814972611077298\n",
      "AUC: 0.7782165585631011\n",
      "Logloss: 7.997324824903003\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.749613601236476\n",
      "Test Accuracy:  0.7453646477132262\n",
      "Sensitivity (Recall): 0.7577639751552795\n",
      "Precision: 0.7376058041112454\n",
      "F1_score: 0.7475490196078433\n",
      "AUC: 0.7454256530142942\n",
      "Logloss: 9.177988378440213\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.7865533230293663\n",
      "Test Accuracy:  0.7676143386897404\n",
      "Sensitivity (Recall): 0.8248447204968944\n",
      "Precision: 0.7385984427141268\n",
      "F1_score: 0.779342723004695\n",
      "AUC: 0.7678959149839945\n",
      "Logloss: 8.376028228867769\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7849196538936959\n",
      "Sensitivity (Recall): 0.8124223602484472\n",
      "Precision: 0.7685076380728555\n",
      "F1_score: 0.7898550724637681\n",
      "AUC: 0.785054968562108\n",
      "Logloss: 7.752281445866977\n",
      "\n",
      "-------Feature Subset: freq_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.6706336939721793\n",
      "Test Accuracy:  0.6650185414091471\n",
      "Sensitivity (Recall): 0.6149068322981367\n",
      "Precision: 0.6808803301237965\n",
      "F1_score: 0.6462140992167104\n",
      "AUC: 0.6647719893348002\n",
      "Logloss: 12.073955585229603\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.6081582200247219\n",
      "Sensitivity (Recall): 0.5813664596273292\n",
      "Precision: 0.611764705882353\n",
      "F1_score: 0.5961783439490447\n",
      "AUC: 0.608026403245399\n",
      "Logloss: 14.123409300803628\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.7958268933539413\n",
      "Test Accuracy:  0.6056860321384425\n",
      "Sensitivity (Recall): 0.3875776397515528\n",
      "Precision: 0.6827133479212254\n",
      "F1_score: 0.49445324881141045\n",
      "AUC: 0.6046129281168588\n",
      "Logloss: 14.212515984089455\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.8091190108191654\n",
      "Test Accuracy:  0.6174289245982695\n",
      "Sensitivity (Recall): 0.5987577639751552\n",
      "Precision: 0.6195372750642674\n",
      "F1_score: 0.6089703095388502\n",
      "AUC: 0.6173370615693734\n",
      "Logloss: 13.789259238481778\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.676661514683153\n",
      "Test Accuracy:  0.6779975278121138\n",
      "Sensitivity (Recall): 0.639751552795031\n",
      "Precision: 0.6903485254691689\n",
      "F1_score: 0.6640876853642812\n",
      "AUC: 0.6778093557333089\n",
      "Logloss: 11.606145497979009\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7026275115919629\n",
      "Test Accuracy:  0.6532756489493201\n",
      "Sensitivity (Recall): 0.6447204968944099\n",
      "Precision: 0.6536523929471033\n",
      "F1_score: 0.649155722326454\n",
      "AUC: 0.6532335571802923\n",
      "Logloss: 12.497212330837282\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.6563658838071693\n",
      "Sensitivity (Recall): 0.6236024844720497\n",
      "Precision: 0.6649006622516557\n",
      "F1_score: 0.6435897435897436\n",
      "AUC: 0.6562046862704651\n",
      "Logloss: 12.385828976729996\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.6639876352395673\n",
      "Test Accuracy:  0.6699629171817059\n",
      "Sensitivity (Recall): 0.6571428571428571\n",
      "Precision: 0.6721728081321474\n",
      "F1_score: 0.664572864321608\n",
      "AUC: 0.6698998418555614\n",
      "Logloss: 11.895742218657949\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.6777434312210201\n",
      "Test Accuracy:  0.6749072929542645\n",
      "Sensitivity (Recall): 0.6670807453416149\n",
      "Precision: 0.6754716981132075\n",
      "F1_score: 0.6712499999999999\n",
      "AUC: 0.6748687859549404\n",
      "Logloss: 11.717528852086293\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.6334981458590853\n",
      "Sensitivity (Recall): 0.6248447204968944\n",
      "Precision: 0.6335012594458438\n",
      "F1_score: 0.6291432145090682\n",
      "AUC: 0.6334555705805506\n",
      "Logloss: 13.2100657971239\n",
      "\n",
      "-------Feature Subset: mfcc_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7230293663060278\n",
      "Test Accuracy:  0.7268232385661311\n",
      "Sensitivity (Recall): 0.7118012422360248\n",
      "Precision: 0.7318007662835249\n",
      "F1_score: 0.7216624685138538\n",
      "AUC: 0.7267493296050973\n",
      "Logloss: 9.846288503083919\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8133498145859085\n",
      "Sensitivity (Recall): 0.8161490683229814\n",
      "Precision: 0.8101109741060419\n",
      "F1_score: 0.8131188118811883\n",
      "AUC: 0.8133635870520195\n",
      "Logloss: 6.727554588079963\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9046367851622875\n",
      "Test Accuracy:  0.76946847960445\n",
      "Sensitivity (Recall): 0.6211180124223602\n",
      "Precision: 0.8802816901408451\n",
      "F1_score: 0.7283321194464676\n",
      "AUC: 0.768738588006998\n",
      "Logloss: 8.309198216403397\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9166924265842349\n",
      "Test Accuracy:  0.7830655129789864\n",
      "Sensitivity (Recall): 0.7888198757763976\n",
      "Precision: 0.7781862745098039\n",
      "F1_score: 0.783466995681678\n",
      "AUC: 0.7830938247270672\n",
      "Logloss: 7.8191114583313475\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.8545595054095827\n",
      "Test Accuracy:  0.796044499381953\n",
      "Sensitivity (Recall): 0.7950310559006211\n",
      "Precision: 0.7950310559006211\n",
      "F1_score: 0.7950310559006211\n",
      "AUC: 0.7960395131901629\n",
      "Logloss: 7.351301371080754\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7935085007727976\n",
      "Test Accuracy:  0.7274412855377008\n",
      "Sensitivity (Recall): 0.715527950310559\n",
      "Precision: 0.7309644670050761\n",
      "F1_score: 0.7231638418079096\n",
      "AUC: 0.7273826713422413\n",
      "Logloss: 9.824011832262462\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7929542645241038\n",
      "Sensitivity (Recall): 0.8\n",
      "Precision: 0.7872860635696821\n",
      "F1_score: 0.7935921133703019\n",
      "AUC: 0.7929889298892989\n",
      "Logloss: 7.462684725188038\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7493044822256569\n",
      "Test Accuracy:  0.7428924598269468\n",
      "Sensitivity (Recall): 0.760248447204969\n",
      "Precision: 0.732934131736527\n",
      "F1_score: 0.7463414634146341\n",
      "AUC: 0.7429778521387698\n",
      "Logloss: 9.26709506172604\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.8205564142194745\n",
      "Test Accuracy:  0.7781211372064277\n",
      "Sensitivity (Recall): 0.7850931677018633\n",
      "Precision: 0.7726161369193154\n",
      "F1_score: 0.7788046826863833\n",
      "AUC: 0.7781554399394925\n",
      "Logloss: 7.997324824903003\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7948084054388134\n",
      "Sensitivity (Recall): 0.8\n",
      "Precision: 0.7901840490797546\n",
      "F1_score: 0.7950617283950616\n",
      "AUC: 0.7948339483394834\n",
      "Logloss: 7.3958547127236685\n",
      "\n",
      "-------Feature Subset: mel_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7171561051004637\n",
      "Test Accuracy:  0.7033374536464772\n",
      "Sensitivity (Recall): 0.7093167701863354\n",
      "Precision: 0.6988984088127295\n",
      "F1_score: 0.7040690505548706\n",
      "AUC: 0.7033668721780386\n",
      "Logloss: 10.692801994299279\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8541409147095179\n",
      "Sensitivity (Recall): 0.884472049689441\n",
      "Precision: 0.8327485380116959\n",
      "F1_score: 0.8578313253012049\n",
      "AUC: 0.854290145385926\n",
      "Logloss: 5.257294313863811\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9245749613601236\n",
      "Test Accuracy:  0.8065512978986403\n",
      "Sensitivity (Recall): 0.6782608695652174\n",
      "Precision: 0.91\n",
      "F1_score: 0.7772241992882563\n",
      "AUC: 0.8059201026792877\n",
      "Logloss: 6.972597967115989\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9278207109737249\n",
      "Test Accuracy:  0.8121137206427689\n",
      "Sensitivity (Recall): 0.8248447204968944\n",
      "Precision: 0.8029020556227328\n",
      "F1_score: 0.8137254901960784\n",
      "AUC: 0.8121763577884226\n",
      "Logloss: 6.7721079297228775\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9210200927357033\n",
      "Test Accuracy:  0.7991347342398022\n",
      "Sensitivity (Recall): 0.7975155279503106\n",
      "Precision: 0.7985074626865671\n",
      "F1_score: 0.798011187072716\n",
      "AUC: 0.7991267676651922\n",
      "Logloss: 7.23991801697347\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.767387944358578\n",
      "Test Accuracy:  0.703955500618047\n",
      "Sensitivity (Recall): 0.7142857142857143\n",
      "Precision: 0.6978155339805825\n",
      "F1_score: 0.7059545733578884\n",
      "AUC: 0.7040063257775435\n",
      "Logloss: 10.670525323477822\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.765142150803461\n",
      "Sensitivity (Recall): 0.7751552795031056\n",
      "Precision: 0.7582017010935601\n",
      "F1_score: 0.7665847665847666\n",
      "AUC: 0.7651914158893142\n",
      "Logloss: 8.465134912153596\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7075734157650696\n",
      "Test Accuracy:  0.6996291718170581\n",
      "Sensitivity (Recall): 0.7180124223602484\n",
      "Precision: 0.6905615292712067\n",
      "F1_score: 0.7040194884287455\n",
      "AUC: 0.6997196183141956\n",
      "Logloss: 10.82646201922802\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.8510046367851622\n",
      "Test Accuracy:  0.723114956736712\n",
      "Sensitivity (Recall): 0.7763975155279503\n",
      "Precision: 0.6998880179171333\n",
      "F1_score: 0.7361601884570083\n",
      "AUC: 0.723377109547493\n",
      "Logloss: 9.979948528012661\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7682323856613102\n",
      "Sensitivity (Recall): 0.7801242236024845\n",
      "Precision: 0.7602905569007264\n",
      "F1_score: 0.7700797057020233\n",
      "AUC: 0.768290894089065\n",
      "Logloss: 8.353751558046312\n",
      "\n",
      "-------Feature Subset: chr_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.6041731066460587\n",
      "Test Accuracy:  0.5914709517923362\n",
      "Sensitivity (Recall): 0.45590062111801244\n",
      "Precision: 0.6220338983050847\n",
      "F1_score: 0.5261648745519713\n",
      "AUC: 0.5908039390952915\n",
      "Logloss: 14.724879412982965\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8096415327564895\n",
      "Sensitivity (Recall): 0.8186335403726708\n",
      "Precision: 0.8026796589524969\n",
      "F1_score: 0.8105781057810578\n",
      "AUC: 0.8096857738763723\n",
      "Logloss: 6.861214613008704\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9131375579598145\n",
      "Test Accuracy:  0.7299134734239803\n",
      "Sensitivity (Recall): 0.5664596273291925\n",
      "Precision: 0.8382352941176471\n",
      "F1_score: 0.676056338028169\n",
      "AUC: 0.7291092724591842\n",
      "Logloss: 9.734905148976635\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9108191653786708\n",
      "Test Accuracy:  0.73053152039555\n",
      "Sensitivity (Recall): 0.7279503105590062\n",
      "Precision: 0.7297633872976339\n",
      "F1_score: 0.7288557213930348\n",
      "AUC: 0.7305188207161575\n",
      "Logloss: 9.712628478155178\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9880989180834622\n",
      "Test Accuracy:  0.7731767614338689\n",
      "Sensitivity (Recall): 0.7677018633540372\n",
      "Precision: 0.7744360902255639\n",
      "F1_score: 0.7710542732376793\n",
      "AUC: 0.7731498246659485\n",
      "Logloss: 8.175538191474656\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.6763523956723339\n",
      "Test Accuracy:  0.6131025957972805\n",
      "Sensitivity (Recall): 0.5018633540372671\n",
      "Precision: 0.6422893481717011\n",
      "F1_score: 0.5634588563458857\n",
      "AUC: 0.612555293254796\n",
      "Logloss: 13.945195934231974\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7064276885043264\n",
      "Sensitivity (Recall): 0.6732919254658385\n",
      "Precision: 0.7188328912466844\n",
      "F1_score: 0.6953175112251443\n",
      "AUC: 0.7062646589198811\n",
      "Logloss: 10.581418640191995\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.6057187017001545\n",
      "Test Accuracy:  0.592707045735476\n",
      "Sensitivity (Recall): 0.5813664596273292\n",
      "Precision: 0.5924050632911393\n",
      "F1_score: 0.5868338557993731\n",
      "AUC: 0.5926512494938614\n",
      "Logloss: 14.680326071340051\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.8391035548686244\n",
      "Test Accuracy:  0.6433868974042027\n",
      "Sensitivity (Recall): 0.6720496894409937\n",
      "Precision: 0.6334894613583139\n",
      "F1_score: 0.6522001205545509\n",
      "AUC: 0.6435279197512471\n",
      "Logloss: 12.853639063980593\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.6872682323856613\n",
      "Sensitivity (Recall): 0.675776397515528\n",
      "Precision: 0.6894803548795945\n",
      "F1_score: 0.6825595984943539\n",
      "AUC: 0.6872116919926963\n",
      "Logloss: 11.271995435657157\n",
      "\n",
      "-------Feature Subset: ton_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.5627511591962906\n",
      "Test Accuracy:  0.5438813349814586\n",
      "Sensitivity (Recall): 0.32298136645962733\n",
      "Precision: 0.5739514348785872\n",
      "F1_score: 0.41335453100158986\n",
      "AUC: 0.5427944962679441\n",
      "Logloss: 16.44018306623514\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.5896168108776267\n",
      "Sensitivity (Recall): 0.5900621118012422\n",
      "Precision: 0.5871446229913473\n",
      "F1_score: 0.5885997521685254\n",
      "AUC: 0.5896190017800799\n",
      "Logloss: 14.791709425447333\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.7845440494590418\n",
      "Test Accuracy:  0.572929542645241\n",
      "Sensitivity (Recall): 0.3391304347826087\n",
      "Precision: 0.6319444444444444\n",
      "F1_score: 0.4413904607922392\n",
      "AUC: 0.5717792395315258\n",
      "Logloss: 15.393179537626668\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.7938176197836166\n",
      "Test Accuracy:  0.5803461063040791\n",
      "Sensitivity (Recall): 0.5652173913043478\n",
      "Precision: 0.5803571428571429\n",
      "F1_score: 0.5726872246696035\n",
      "AUC: 0.5802716722819401\n",
      "Logloss: 15.125859487769187\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.6200927357032457\n",
      "Test Accuracy:  0.5618046971569839\n",
      "Sensitivity (Recall): 0.4062111801242236\n",
      "Precision: 0.5860215053763441\n",
      "F1_score: 0.47982391782831996\n",
      "AUC: 0.5610391693979052\n",
      "Logloss: 15.794159612412892\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.5973724884080371\n",
      "Test Accuracy:  0.5321384425216317\n",
      "Sensitivity (Recall): 0.4956521739130435\n",
      "Precision: 0.532\n",
      "F1_score: 0.5131832797427653\n",
      "AUC: 0.5319589282849351\n",
      "Logloss: 16.86343981184282\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.5673671199011124\n",
      "Sensitivity (Recall): 0.546583850931677\n",
      "Precision: 0.567741935483871\n",
      "F1_score: 0.5569620253164558\n",
      "AUC: 0.5672648651952359\n",
      "Logloss: 15.593669575019781\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.5165378670788253\n",
      "Test Accuracy:  0.5197775030902348\n",
      "Sensitivity (Recall): 0.5416149068322982\n",
      "Precision: 0.5165876777251185\n",
      "F1_score: 0.5288053365676167\n",
      "AUC: 0.5198849441910568\n",
      "Logloss: 17.308973228271956\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.6353941267387945\n",
      "Test Accuracy:  0.542027194066749\n",
      "Sensitivity (Recall): 0.5279503105590062\n",
      "Precision: 0.5407124681933843\n",
      "F1_score: 0.5342551854179762\n",
      "AUC: 0.5419579351073014\n",
      "Logloss: 16.50701307869951\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.5482076637824475\n",
      "Sensitivity (Recall): 0.55527950310559\n",
      "Precision: 0.5451219512195122\n",
      "F1_score: 0.5501538461538462\n",
      "AUC: 0.5482424575798553\n",
      "Logloss: 16.284246370484944\n",
      "\n",
      "-------Feature Subset: spectral_features -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7442040185471407\n",
      "Test Accuracy:  0.7428924598269468\n",
      "Sensitivity (Recall): 0.7254658385093168\n",
      "Precision: 0.7496790757381258\n",
      "F1_score: 0.7373737373737375\n",
      "AUC: 0.7428067199926658\n",
      "Logloss: 9.26709506172604\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9326328800988876\n",
      "Sensitivity (Recall): 0.9490683229813665\n",
      "Precision: 0.9182692307692307\n",
      "F1_score: 0.93341478313989\n",
      "AUC: 0.9327137432865013\n",
      "Logloss: 2.4281571195387945\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9680061823802164\n",
      "Test Accuracy:  0.8671199011124846\n",
      "Sensitivity (Recall): 0.7751552795031056\n",
      "Precision: 0.9483282674772037\n",
      "F1_score: 0.8530416951469583\n",
      "AUC: 0.8666674306494618\n",
      "Logloss: 4.789484226613219\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.969242658423493\n",
      "Test Accuracy:  0.8714462299134734\n",
      "Sensitivity (Recall): 0.884472049689441\n",
      "Precision: 0.8609431680773881\n",
      "F1_score: 0.8725490196078431\n",
      "AUC: 0.871510317587648\n",
      "Logloss: 4.633547530863021\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9996908809891808\n",
      "Test Accuracy:  0.907292954264524\n",
      "Sensitivity (Recall): 0.9204968944099379\n",
      "Precision: 0.8960096735187424\n",
      "F1_score: 0.9080882352941176\n",
      "AUC: 0.9073579182996798\n",
      "Logloss: 3.3415006232185247\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7984544049459041\n",
      "Test Accuracy:  0.7187886279357231\n",
      "Sensitivity (Recall): 0.6695652173913044\n",
      "Precision: 0.7403846153846154\n",
      "F1_score: 0.7031963470319634\n",
      "AUC: 0.7185464463340286\n",
      "Logloss: 10.135885223762857\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8164400494437577\n",
      "Sensitivity (Recall): 0.8186335403726708\n",
      "Precision: 0.8135802469135802\n",
      "F1_score: 0.8160990712074303\n",
      "AUC: 0.8164508415270487\n",
      "Logloss: 6.616171233972679\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7548686244204018\n",
      "Test Accuracy:  0.7379480840543882\n",
      "Sensitivity (Recall): 0.7577639751552795\n",
      "Precision: 0.7270560190703218\n",
      "F1_score: 0.7420924574209246\n",
      "AUC: 0.7380455792135561\n",
      "Logloss: 9.445308428297697\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.941112828438949\n",
      "Test Accuracy:  0.7818294190358467\n",
      "Sensitivity (Recall): 0.8484472049689441\n",
      "Precision: 0.7472647702407003\n",
      "F1_score: 0.7946480511925539\n",
      "AUC: 0.7821571818202655\n",
      "Logloss: 7.863664799974261\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8343634116192831\n",
      "Sensitivity (Recall): 0.8347826086956521\n",
      "Precision: 0.8327137546468402\n",
      "F1_score: 0.8337468982630272\n",
      "AUC: 0.8343654740895236\n",
      "Logloss: 5.97014778015043\n",
      "\n",
      "-------Feature Subset: music -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.5979907264296754\n",
      "Test Accuracy:  0.584672435105068\n",
      "Sensitivity (Recall): 0.37142857142857144\n",
      "Precision: 0.6430107526881721\n",
      "F1_score: 0.47086614173228347\n",
      "AUC: 0.5836232648040766\n",
      "Logloss: 14.96992279201899\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8751545117428925\n",
      "Sensitivity (Recall): 0.8770186335403727\n",
      "Precision: 0.8726823238566132\n",
      "F1_score: 0.8748451053283767\n",
      "AUC: 0.8751636833138517\n",
      "Logloss: 4.4998875059342796\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9381761978361669\n",
      "Test Accuracy:  0.7867737948084055\n",
      "Sensitivity (Recall): 0.639751552795031\n",
      "Precision: 0.9035087719298246\n",
      "F1_score: 0.7490909090909091\n",
      "AUC: 0.786050438144133\n",
      "Logloss: 7.685451433402607\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9406491499227202\n",
      "Test Accuracy:  0.7873918417799752\n",
      "Sensitivity (Recall): 0.7925465838509317\n",
      "Precision: 0.7828220858895706\n",
      "F1_score: 0.7876543209876543\n",
      "AUC: 0.7874172033645803\n",
      "Logloss: 7.66317476258115\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8467243510506799\n",
      "Sensitivity (Recall): 0.8459627329192546\n",
      "Precision: 0.8459627329192546\n",
      "F1_score: 0.8459627329192546\n",
      "AUC: 0.8467206038520013\n",
      "Logloss: 5.524614363721294\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.6823802163833076\n",
      "Test Accuracy:  0.6180469715698393\n",
      "Sensitivity (Recall): 0.5341614906832298\n",
      "Precision: 0.6389301634472511\n",
      "F1_score: 0.5818673883626523\n",
      "AUC: 0.6176342508766703\n",
      "Logloss: 13.766982567660321\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7206427688504327\n",
      "Sensitivity (Recall): 0.6968944099378882\n",
      "Precision: 0.729518855656697\n",
      "F1_score: 0.7128335451080051\n",
      "AUC: 0.720525925756152\n",
      "Logloss: 10.069055211298485\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.6058732612055642\n",
      "Test Accuracy:  0.5945611866501854\n",
      "Sensitivity (Recall): 0.5863354037267081\n",
      "Precision: 0.5937106918238994\n",
      "F1_score: 0.5900000000000001\n",
      "AUC: 0.5945207153934894\n",
      "Logloss: 14.613496058875679\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.8627511591962905\n",
      "Test Accuracy:  0.6656365883807169\n",
      "Sensitivity (Recall): 0.5527950310559007\n",
      "Precision: 0.7108626198083067\n",
      "F1_score: 0.6219426974143956\n",
      "AUC: 0.6650814023668187\n",
      "Logloss: 12.051678914408145\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.7367119901112484\n",
      "Sensitivity (Recall): 0.724223602484472\n",
      "Precision: 0.7407878017789072\n",
      "F1_score: 0.7324120603015075\n",
      "AUC: 0.7366505466296899\n",
      "Logloss: 9.48986176994061\n",
      "\n",
      "-------Feature Subset: coeffs -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.738485316846986\n",
      "Test Accuracy:  0.7311495673671199\n",
      "Sensitivity (Recall): 0.6807453416149069\n",
      "Precision: 0.7548209366391184\n",
      "F1_score: 0.7158719790986283\n",
      "AUC: 0.7309015760965063\n",
      "Logloss: 9.690351807333721\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9740420271940667\n",
      "Sensitivity (Recall): 0.9763975155279503\n",
      "Precision: 0.9715698393077874\n",
      "F1_score: 0.9739776951672863\n",
      "AUC: 0.9740536163125607\n",
      "Logloss: 0.9356201745011872\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9853168469860897\n",
      "Test Accuracy:  0.9351050679851669\n",
      "Sensitivity (Recall): 0.8819875776397516\n",
      "Precision: 0.9861111111111112\n",
      "F1_score: 0.9311475409836065\n",
      "AUC: 0.9348437273192607\n",
      "Logloss: 2.3390504362529674\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9842349304482225\n",
      "Test Accuracy:  0.9245982694684796\n",
      "Sensitivity (Recall): 0.9440993788819876\n",
      "Precision: 0.9080047789725209\n",
      "F1_score: 0.925700365408039\n",
      "AUC: 0.9246942158862581\n",
      "Logloss: 2.7177538402177333\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9468479604449939\n",
      "Sensitivity (Recall): 0.9664596273291925\n",
      "Precision: 0.929510155316607\n",
      "F1_score: 0.9476248477466505\n",
      "AUC: 0.9469444508109678\n",
      "Logloss: 1.9157936906452875\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.7965996908809891\n",
      "Test Accuracy:  0.7194066749072929\n",
      "Sensitivity (Recall): 0.7403726708074534\n",
      "Precision: 0.7086801426872771\n",
      "F1_score: 0.724179829890644\n",
      "AUC: 0.7195098286386591\n",
      "Logloss: 10.113608552941402\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8152039555006181\n",
      "Sensitivity (Recall): 0.8149068322981367\n",
      "Precision: 0.8138957816377171\n",
      "F1_score: 0.8144009931719429\n",
      "AUC: 0.8152024936398433\n",
      "Logloss: 6.660724575615593\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.759969088098918\n",
      "Test Accuracy:  0.734857849196539\n",
      "Sensitivity (Recall): 0.7552795031055901\n",
      "Precision: 0.7238095238095238\n",
      "F1_score: 0.739209726443769\n",
      "AUC: 0.734958324738527\n",
      "Logloss: 9.55669178240498\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.9828438948995363\n",
      "Test Accuracy:  0.8349814585908529\n",
      "Sensitivity (Recall): 0.8571428571428571\n",
      "Precision: 0.8194774346793349\n",
      "F1_score: 0.8378870673952641\n",
      "AUC: 0.8350904937620804\n",
      "Logloss: 5.9478711093289744\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8603213844252163\n",
      "Sensitivity (Recall): 0.867080745341615\n",
      "Precision: 0.8543451652386781\n",
      "F1_score: 0.8606658446362516\n",
      "AUC: 0.8603546408134888\n",
      "Logloss: 5.034527605649244\n",
      "\n",
      "-------Feature Subset: comb_domain -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7431221020092735\n",
      "Test Accuracy:  0.7404202719406675\n",
      "Sensitivity (Recall): 0.7192546583850932\n",
      "Precision: 0.7490297542043984\n",
      "F1_score: 0.7338403041825095\n",
      "AUC: 0.7403161360806155\n",
      "Logloss: 9.35620174501187\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8522867737948084\n",
      "Sensitivity (Recall): 0.8720496894409938\n",
      "Precision: 0.837708830548926\n",
      "F1_score: 0.8545343883140596\n",
      "AUC: 0.8523840083121328\n",
      "Logloss: 5.3241243263281826\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9194744976816074\n",
      "Test Accuracy:  0.8133498145859085\n",
      "Sensitivity (Recall): 0.6931677018633541\n",
      "Precision: 0.9102773246329527\n",
      "F1_score: 0.7870239774330043\n",
      "AUC: 0.8127585126782946\n",
      "Logloss: 6.727554588079964\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9224111282843895\n",
      "Test Accuracy:  0.8250927070457355\n",
      "Sensitivity (Recall): 0.8322981366459627\n",
      "Precision: 0.8190709046454768\n",
      "F1_score: 0.8256315465187924\n",
      "AUC: 0.8251281581138793\n",
      "Logloss: 6.304297842472283\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  0.9123647604327666\n",
      "Test Accuracy:  0.8294190358467244\n",
      "Sensitivity (Recall): 0.8422360248447205\n",
      "Precision: 0.8198307134220073\n",
      "F1_score: 0.8308823529411765\n",
      "AUC: 0.8294820960631967\n",
      "Logloss: 6.1483611467220864\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.8010819165378671\n",
      "Test Accuracy:  0.7583436341161929\n",
      "Sensitivity (Recall): 0.7751552795031056\n",
      "Precision: 0.7482014388489209\n",
      "F1_score: 0.7614399023794998\n",
      "AUC: 0.7584263482386376\n",
      "Logloss: 8.71017829118962\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.826946847960445\n",
      "Sensitivity (Recall): 0.853416149068323\n",
      "Precision: 0.8091872791519434\n",
      "F1_score: 0.8307134220072552\n",
      "AUC: 0.8270770782241985\n",
      "Logloss: 6.237467830007914\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7553323029366306\n",
      "Test Accuracy:  0.7533992583436341\n",
      "Sensitivity (Recall): 0.7515527950310559\n",
      "Precision: 0.7524875621890548\n",
      "F1_score: 0.7520198881292729\n",
      "AUC: 0.7533901736532893\n",
      "Logloss: 8.888391657761275\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.8693972179289027\n",
      "Test Accuracy:  0.8182941903584673\n",
      "Sensitivity (Recall): 0.8074534161490683\n",
      "Precision: 0.8238276299112801\n",
      "F1_score: 0.8155583437892095\n",
      "AUC: 0.8182408532159855\n",
      "Logloss: 6.549341221508308\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8349814585908529\n",
      "Sensitivity (Recall): 0.8546583850931677\n",
      "Precision: 0.8210023866348448\n",
      "F1_score: 0.837492391965916\n",
      "AUC: 0.8350782700373588\n",
      "Logloss: 5.9478711093289744\n",
      "\n",
      "-------Feature Subset: no_music -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7510046367851623\n",
      "Test Accuracy:  0.7472187886279357\n",
      "Sensitivity (Recall): 0.7254658385093168\n",
      "Precision: 0.7564766839378239\n",
      "F1_score: 0.7406467977171844\n",
      "AUC: 0.7471117630430963\n",
      "Logloss: 9.111158365975845\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.946229913473424\n",
      "Sensitivity (Recall): 0.9515527950310559\n",
      "Precision: 0.941031941031941\n",
      "F1_score: 0.9462631253860407\n",
      "AUC: 0.9462561023125761\n",
      "Logloss: 1.9380703614667443\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9782071097372489\n",
      "Test Accuracy:  0.8893695920889988\n",
      "Sensitivity (Recall): 0.8049689440993789\n",
      "Precision: 0.9671641791044776\n",
      "F1_score: 0.8786440677966102\n",
      "AUC: 0.8889543367483363\n",
      "Logloss: 3.9875240770407734\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.9768160741885626\n",
      "Test Accuracy:  0.8881334981458591\n",
      "Sensitivity (Recall): 0.8944099378881988\n",
      "Precision: 0.8823529411764706\n",
      "F1_score: 0.8883405305367058\n",
      "AUC: 0.8881643785381954\n",
      "Logloss: 4.032077418683687\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.930778739184178\n",
      "Sensitivity (Recall): 0.9515527950310559\n",
      "Precision: 0.9129916567342073\n",
      "F1_score: 0.9318734793187348\n",
      "AUC: 0.9308809485610384\n",
      "Logloss: 2.494987132003165\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.8307573415765069\n",
      "Test Accuracy:  0.7503090234857849\n",
      "Sensitivity (Recall): 0.7279503105590062\n",
      "Precision: 0.7600518806744487\n",
      "F1_score: 0.7436548223350253\n",
      "AUC: 0.7501990175181255\n",
      "Logloss: 8.999775011868559\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8399258343634116\n",
      "Sensitivity (Recall): 0.8658385093167702\n",
      "Precision: 0.8219339622641509\n",
      "F1_score: 0.8433151845130066\n",
      "AUC: 0.8400533259990985\n",
      "Logloss: 5.769657742757319\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7690880989180835\n",
      "Test Accuracy:  0.7453646477132262\n",
      "Sensitivity (Recall): 0.7440993788819876\n",
      "Precision: 0.7440993788819876\n",
      "F1_score: 0.7440993788819876\n",
      "AUC: 0.7453584225283246\n",
      "Logloss: 9.177988378440215\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.971870170015456\n",
      "Test Accuracy:  0.8368355995055624\n",
      "Sensitivity (Recall): 0.8434782608695652\n",
      "Precision: 0.8310893512851897\n",
      "F1_score: 0.8372379778051787\n",
      "AUC: 0.8368682817262956\n",
      "Logloss: 5.881041096864603\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8634116192830655\n",
      "Sensitivity (Recall): 0.8881987577639752\n",
      "Precision: 0.8451536643026005\n",
      "F1_score: 0.8661417322834647\n",
      "AUC: 0.863533573223931\n",
      "Logloss: 4.9231442515419594\n",
      "\n",
      "-------Feature Subset: all -------\n",
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7471406491499227\n",
      "Test Accuracy:  0.7330037082818294\n",
      "Sensitivity (Recall): 0.684472049689441\n",
      "Precision: 0.7558299039780522\n",
      "F1_score: 0.7183833116036505\n",
      "AUC: 0.7327649301337733\n",
      "Logloss: 9.62352179486935\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN1 model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9814585908529048\n",
      "Sensitivity (Recall): 0.9838509316770186\n",
      "Precision: 0.9789864029666254\n",
      "F1_score: 0.9814126394052045\n",
      "AUC: 0.9814703612874638\n",
      "Logloss: 0.6683001246437051\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN2 model ====\n",
      "Training Accuracy:  0.9882534775888717\n",
      "Test Accuracy:  0.9369592088998764\n",
      "Sensitivity (Recall): 0.8832298136645963\n",
      "Precision: 0.9888734353268428\n",
      "F1_score: 0.9330708661417323\n",
      "AUC: 0.9366948576318062\n",
      "Logloss: 2.272220423788597\n",
      "\n",
      "\n",
      "==== Stats_dict for the K-NN3 model ====\n",
      "Training Accuracy:  0.98516228748068\n",
      "Test Accuracy:  0.9369592088998764\n",
      "Sensitivity (Recall): 0.9490683229813665\n",
      "Precision: 0.926060606060606\n",
      "F1_score: 0.9374233128834356\n",
      "AUC: 0.9370187863369318\n",
      "Logloss: 2.2722204237885966\n",
      "\n",
      "\n",
      "==== Stats_dict for the SVM model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.9375772558714462\n",
      "Sensitivity (Recall): 0.9751552795031055\n",
      "Precision: 0.9064665127020786\n",
      "F1_score: 0.9395571514063434\n",
      "AUC: 0.9377621415965712\n",
      "Logloss: 2.2499437529671398\n",
      "\n",
      "\n",
      "==== Stats_dict for the DTC model ====\n",
      "Training Accuracy:  0.8343122102009274\n",
      "Test Accuracy:  0.745982694684796\n",
      "Sensitivity (Recall): 0.7279503105590062\n",
      "Precision: 0.7532133676092545\n",
      "F1_score: 0.7403663929248263\n",
      "AUC: 0.745893974467695\n",
      "Logloss: 9.155711707618758\n",
      "\n",
      "\n",
      "==== Stats_dict for the RFC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.842398022249691\n",
      "Sensitivity (Recall): 0.8633540372670807\n",
      "Precision: 0.8273809523809523\n",
      "F1_score: 0.8449848024316109\n",
      "AUC: 0.8425011268746228\n",
      "Logloss: 5.680551059471492\n",
      "\n",
      "\n",
      "==== Stats_dict for the Logistic Regression model ====\n",
      "Training Accuracy:  0.7712519319938176\n",
      "Test Accuracy:  0.7404202719406675\n",
      "Sensitivity (Recall): 0.7453416149068323\n",
      "Precision: 0.7361963190184049\n",
      "F1_score: 0.7407407407407407\n",
      "AUC: 0.7404444851901936\n",
      "Logloss: 9.35620174501187\n",
      "\n",
      "\n",
      "==== Stats_dict for the NN model ====\n",
      "Training Accuracy:  0.982225656877898\n",
      "Test Accuracy:  0.8677379480840544\n",
      "Sensitivity (Recall): 0.8919254658385093\n",
      "Precision: 0.8497041420118343\n",
      "F1_score: 0.8703030303030304\n",
      "AUC: 0.8678569518614441\n",
      "Logloss: 4.767207555791762\n",
      "\n",
      "\n",
      "==== Stats_dict for the GBC model ====\n",
      "Training Accuracy:  1.0\n",
      "Test Accuracy:  0.8745364647713226\n",
      "Sensitivity (Recall): 0.8919254658385093\n",
      "Precision: 0.8609112709832134\n",
      "F1_score: 0.8761439902379501\n",
      "AUC: 0.8746220195121205\n",
      "Logloss: 4.522164176755736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in feature_subsets:\n",
    "    print(\"-------Feature Subset: {} -------\".format(k))\n",
    "    data = data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "    for model in models:\n",
    "        model_training(data, model, stats=True, cm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('outs/{}_feature_perf.csv'.format(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_results = {}\n",
    "reduced_dataset1 = channel_selection(dataset, [\"Cz\",\"CP3\",\"CPz\",\"P3\", 'O1'])\n",
    "for model in models:\n",
    "    for k in feature_subsets:\n",
    "        data = data_preparation(dataset=reduced_dataset1, feature_subset=feature_subsets[k])\n",
    "        feature_results[k] = model_training(data, model, stats=False, cm=False)\n",
    "\n",
    "    features_perf_df = pd.DataFrame.from_dict(feature_results)\n",
    "    features_perf_df.to_csv('{}_feature_perfO1.csv'.format(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Denemesi, sonra training.py'a eklenecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== Stats_dict for the K-NN model ====\n",
      "Training Accuracy:  0.7474497681607419\n",
      "Test Accuracy:  0.7323856613102596\n",
      "Sensitivity (Recall): 0.6832298136645962\n",
      "Precision: 0.7554945054945055\n",
      "F1_score: 0.7175472928897586\n",
      "AUC: 0.732143812121351\n",
      "Logloss: 9.645798465690806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_file = 'eeg_features.csv'\n",
    "models = ['K-NN', 'K-NN1', 'K-NN2', 'K-NN3', 'SVM', 'DTC', 'RFC', 'NN', 'GBC', 'Logistic Regression']\n",
    "dataset = data_loader(path = csv_file)\n",
    "selected_channels = [\"Cz\",\"CP3\",\"CPz\",\"P3\"]\n",
    "reduced_dataset = channel_selection(dataset, selected_channels)\n",
    "all_features = reduced_dataset.columns[:len(reduced_dataset.columns) - 1]\n",
    "data = data_preparation(dataset=reduced_dataset, feature_subset=all_features)\n",
    "model_training(data, 'K-NN', stats=True, cm=False)\n",
    "\n",
    "test_model = KNeighborsClassifier(leaf_size= 10, n_neighbors= int(np.sqrt(np.prod(data[0].shape))), p= 1)\n",
    "X = utils.feature_selection(dataset=reduced_dataset, feature_subset=all_features)\n",
    "\n",
    "labels = reduced_dataset.iloc[:, -1:]\n",
    "y = labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(leaf_size=10, n_neighbors=714, p=1): 0.7185924735103615\n",
      "SVC(): 0.7413451637537811\n",
      "K-NN1: 0.9240867849555825\n",
      "K-NN2: 0.8596640454136482\n",
      "K-NN3: 0.872281529759898\n",
      "SVM: 0.5346212560763153\n",
      "DTC: 0.7601396014074806\n",
      "RFC: 0.8478022066226198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kemalcankucuk/Documents/PAWS Work/paws/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression: 0.7486409464336359\n",
      "NN: 0.500123609394314\n",
      "GBC: 0.8794537030454389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "cv_results = pd.DataFrame()\n",
    "\n",
    "model = KNeighborsClassifier(leaf_size= 10, n_neighbors= int(np.sqrt(np.prod(data[0].shape))), p= 1)\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_results[model] = np.mean(scores)\n",
    "print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "\n",
    "model = SVC()\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "cv_results[model] = np.mean(scores)\n",
    "print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "\n",
    "for model in models[1:len(models)]:\n",
    "    scores = cross_val_score(model_switch(model), X, y, cv=5)\n",
    "    print(\"{}: {}\".format(model, np.mean(scores)))\n",
    "    cv_results[model] = np.mean(scores)\n",
    "\n",
    "cv_results.to_csv('outs/cross_val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

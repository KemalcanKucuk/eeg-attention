{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "#from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.signal import detrend\n",
    "from nolds import dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_parameters(eeg_signal):\n",
    "    # Calculate the first derivative (slope) of the EEG signal\n",
    "    diff_signal = np.diff(eeg_signal)\n",
    "    \n",
    "    # Calculate the variance (activity) of the original signal\n",
    "    activity = np.var(eeg_signal)\n",
    "    \n",
    "    # Calculate the variance (activity) of the first derivative (slope)\n",
    "    mobility = np.var(diff_signal)\n",
    "    \n",
    "    # Calculate the mobility parameter (square root of mobility divided by activity)\n",
    "    mobility /= activity\n",
    "    \n",
    "    # Calculate the second derivative of the EEG signal\n",
    "    diff2_signal = np.diff(diff_signal)\n",
    "    \n",
    "    # Calculate the complexity (square root of the mobility divided by the mobility of the first derivative)\n",
    "    complexity = np.sqrt(mobility / (np.var(diff2_signal) / activity))\n",
    "    \n",
    "    return activity, mobility, complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hedef: feature extractionda butun featurelari cikart, csvde hepsine isim ver, training datasi hazirlarken csvden ihtiyac olani kullan\n",
    "def feature_extraction(signal):\n",
    "\n",
    "    feature_vector = {}\n",
    "    sr = 128\n",
    "    # Timbral Texture Features\n",
    "    \n",
    "    # 0 indices are due to array shape\n",
    "    feature_vector['spc_cnt'] = lrf.spectral_centroid(y=signal, sr=sr)[0][0] # Spectral Centroid\n",
    "    feature_vector['spc_roff'] = lrf.spectral_rolloff(y=signal, sr=sr)[0][0] # Rolloff\n",
    "    feature_vector['zc']  = np.array(np.sum(np.abs(np.diff(np.sign(signal)))) / (2 * len(signal)))\n",
    "\n",
    "    n_mfcc = 10     \n",
    "    for idx, mfcc in enumerate(lrf.mfcc(y=signal, n_mfcc=n_mfcc, sr=sr)): # First 5 MFCCs\n",
    "        feature_vector['mfcc_' + str(idx)] = mfcc[0]\n",
    "    \n",
    "    n_chr = 20\n",
    "    for idx, chroma in enumerate(lrf.chroma_stft(y=signal, n_chroma=n_chr, sr=sr)): #chromagram\n",
    "        feature_vector['chr_' + str(idx)] = chroma[0]\n",
    "\n",
    "    n_mel = 15\n",
    "    for idx, mel in enumerate(lr.power_to_db(lrf.melspectrogram(y=signal, sr=sr))[:n_mel, :]):\n",
    "        feature_vector['mel_' + str(idx)] = mel[0]\n",
    "    \n",
    "    frequency_bands = {\n",
    "    'gamma': (30,64),\n",
    "    'beta': (13, 30),\n",
    "    'alpha': (8, 13),\n",
    "    'theta': (4, 8),\n",
    "    'delta': (1, 4),\n",
    "    }\n",
    "\n",
    "    # Iterate over each frequency band\n",
    "    band_powers = {}\n",
    "    sampling_frequency = 128\n",
    "\n",
    "    # Calculate the power spectral density (PSD) using Welch's method\n",
    "    frequencies, psd = welch(signal, fs=sampling_frequency, nperseg=1024)\n",
    "    \n",
    "\n",
    "    # Iterate over each frequency band\n",
    "    # iterations are reversed due to performance differences in certain models\n",
    "    # TODO: reversing process should be improved, way too clunky rn.\n",
    "    for band, (low_freq, high_freq) in reversed(frequency_bands.items()):\n",
    "        # Find indices corresponding to the specified frequency range\n",
    "        band_indices = np.where((frequencies >= low_freq) & (frequencies < high_freq))\n",
    "        # Integrate PSD within the band's frequency range to compute band power\n",
    "        band_power = np.trapz(psd[band_indices], frequencies[band_indices])\n",
    "        band_powers[band] = band_power\n",
    "        feature_vector[band + '_power'] = band_power\n",
    "    \n",
    "    for band in reversed(list(band_powers)):\n",
    "        for child_band in reversed(list(band_powers)):\n",
    "            if child_band == band:\n",
    "                continue\n",
    "            feature_vector[band + '_' + child_band] = band_powers[band]/ band_powers[child_band]\n",
    "        band_powers.pop(band)\n",
    "    \n",
    "    \n",
    "    # Calculate the first differences\n",
    "    first_differences = np.diff(signal, n=1)\n",
    "\n",
    "    # Calculate the mean of the absolute values of the first differences\n",
    "    feature_vector['mean_abs_sec_dif'] = np.mean(np.abs(first_differences))\n",
    "\n",
    "    feature_vector['dfa'] = dfa(signal, overlap=False)\n",
    "\n",
    "    from scipy.fft import fft, fftfreq\n",
    "    \n",
    "    # Number of sample points\n",
    "    N = sr*3\n",
    "    # sample spacing\n",
    "    T = 1.0 / sr\n",
    "    \n",
    "    yf = fft(signal)\n",
    "    yf = 2.0/N * np.abs(yf[0:N//2])\n",
    "    np.clip(yf, 0, 15)\n",
    "\n",
    "    xf = fftfreq(N, T)[:N//2]\n",
    "    # find peaks with respect to the percentage of the highest value in fft\n",
    "    #height = np.max(yf[1:len(yf)] * 0.35)\n",
    "    height = 0.2\n",
    "    peaks, _ = scipy.signal.find_peaks(yf, height=height)\n",
    "\n",
    "    # frequency of the maximum peak    \n",
    "    #feature_vector['peak_freq'] = xf[yf == np.max(yf[peaks])]\n",
    "\n",
    "    # maximum frequency of peaks\n",
    "    #feature_vector['max_freq'] = xf[peaks][len(xf[peaks]) - 1]\n",
    "    \n",
    "    # peak slope\n",
    "    from scipy import stats\n",
    "    res = stats.linregress(xf[peaks], yf[peaks])\n",
    "    feature_vector['slope'] = res.slope\n",
    "    \n",
    "    feature_vector['skew'] = [stats.skew(signal)][0] #no\n",
    "    feature_vector['kurtosis'] = [stats.kurtosis(signal)][0] #no\n",
    "\n",
    "    activity, mobility, complexity = hjorth_parameters(signal) #no\n",
    "    feature_vector['activity'] = [activity][0]\n",
    "    feature_vector['mobility'] = [mobility][0]\n",
    "    feature_vector['complexity'] = [complexity][0]\n",
    "    feature_vector['rms'] = np.sqrt(np.mean(signal**2))\n",
    "    feature_vector['tempo'] = lr.beat.tempo(y=signal)[0]\n",
    "\n",
    "    n_tonnetz = 15\n",
    "    for idx, tonal in enumerate(lrf.tonnetz(y=signal)[:n_tonnetz, :]):\n",
    "        feature_vector['ton_' + str(idx)] = tonal[0]\n",
    "        \n",
    "    return feature_vector\n",
    "    \n",
    "    # rejected features, discuss whether to include them in the paper or not.\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    [cA5, cD5, cD4, cD3, cD2, cD1] = wavedec(signal, 'db1', level=5)\n",
    "    coeffs = [cA5, cD5, cD4, cD3, cD2, cD1]\n",
    "    db1 = pywt.Wavelet('db1')\n",
    "    \n",
    "    re0 = pywt.waverec([coeffs[0]], db1)\n",
    "    re1 = pywt.waverec([coeffs[1]], db1)\n",
    "    re2 = pywt.waverec([coeffs[2]], db1)\n",
    "    re3 = pywt.waverec([coeffs[3]], db1)\n",
    "    re4 = pywt.waverec([coeffs[4]], db1)\n",
    "    re5 = pywt.waverec([coeffs[5]], db1)\n",
    "    '''\n",
    "\n",
    "\n",
    "    # hata veren featureler\n",
    "\n",
    "    '''    \n",
    "    \n",
    "    # Rhythymic Content Features\n",
    "    peaks = -np.sort(-lr.onset.onset_strength(signal, sr = 128))\n",
    "    A0 = peaks[0]\n",
    "    A1 = peaks[1]\n",
    "    RA = A1/A0    \n",
    "    \n",
    "    extracted_features.append(np.mean(lrf.tempogram(signal)))\n",
    "    extracted_features.append(A0)\n",
    "    extracted_features.append(A1)\n",
    "    extracted_features.append(RA)\n",
    "\n",
    "    '''\n",
    "    #feature_vector.append([lr.onset.onset_strength(signal)]) # Flux\n",
    "    #feature_vector.append(lr.feature.zero_crossing_rate(signal)) # Zero Crossings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'drowsiness-dataset.mat' # changed to relative path\n",
    "data_dict = scipy.io.loadmat(dataset_path)\n",
    "subjects = list(data_dict[\"subindex\"])\n",
    "states = [i[0] for i in data_dict[\"substate\"]]\n",
    "eeg = data_dict[\"EEGsample\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "channel_idx =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "channel_names = dict(zip(channel_names, channel_idx))\n",
    "\n",
    "def select_channel(data, channel_list):\n",
    "    selection = []\n",
    "    channel_col = []\n",
    "    for i in range(len(channel_list)):\n",
    "        selection.append(data[:, channel_names[channel_list[i]], :])\n",
    "        channel_col.append([channel_list[i]] * data.shape[0])\n",
    "    selected_data = np.concatenate(selection)\n",
    "    channel_col = np.concatenate(channel_col)\n",
    "    return selected_data, channel_col\n",
    "\n",
    "channel_list = ['F3', 'F4', 'C3', 'Cz', 'Oz']\n",
    "labels = states * len(channel_list)\n",
    "data, channel_col = select_channel(eeg, channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction on Selected Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "765.3157708644867\n"
     ]
    }
   ],
   "source": [
    "# extracted features np array olabilir liste yerine\n",
    "import time\n",
    "start = time.time()\n",
    "extracted_features = []\n",
    "for i in range(data.shape[0]):\n",
    "    signal_features = feature_extraction(data[i,:])\n",
    "    extracted_features.append(signal_features)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(extracted_features).fillna(0)\n",
    "df.insert(loc = 0, column = 'channels', value = channel_col)\n",
    "df['label'] = labels\n",
    "df.to_csv(\"eeg_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import librosa as lr\n",
    "import librosa.feature as lrf\n",
    "from scipy.signal import welch\n",
    "import pywt\n",
    "from pywt import *\n",
    "from scipy.signal import periodogram\n",
    "#from pyemd import emd\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import linregress, skew, kurtosis\n",
    "from scipy.fft import fft, fftfreq\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "import nolds\n",
    "from pyentrp import entropy as ent\n",
    "from scipy.signal import detrend\n",
    "from nolds import dfa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hjorth_parameters(eeg_signal):\n",
    "    # Calculate the first derivative (slope) of the EEG signal\n",
    "    diff_signal = np.diff(eeg_signal)\n",
    "    \n",
    "    # Calculate the variance (activity) of the original signal\n",
    "    activity = np.var(eeg_signal)\n",
    "    \n",
    "    # Calculate the variance (activity) of the first derivative (slope)\n",
    "    mobility = np.var(diff_signal)\n",
    "    \n",
    "    # Calculate the mobility parameter (square root of mobility divided by activity)\n",
    "    mobility /= activity\n",
    "    \n",
    "    # Calculate the second derivative of the EEG signal\n",
    "    diff2_signal = np.diff(diff_signal)\n",
    "    \n",
    "    # Calculate the complexity (square root of the mobility divided by the mobility of the first derivative)\n",
    "    complexity = np.sqrt(mobility / (np.var(diff2_signal) / activity))\n",
    "    \n",
    "    return activity, mobility, complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 128\n",
    "n_mfcc = 10\n",
    "n_chr = 20\n",
    "n_mel = 15\n",
    "n_tonnetz = 15\n",
    "frequency_bands = {\n",
    "    'gamma': (30,64),\n",
    "    'beta': (13, 30),\n",
    "    'alpha': (8, 13),\n",
    "    'theta': (4, 8),\n",
    "    'delta': (1, 4),\n",
    "    }\n",
    "sampling_frequency = 128\n",
    "\n",
    "# Number of sample points\n",
    "N = sr*3\n",
    "\n",
    "# sample spacing\n",
    "T = 1.0 / sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(signal):\n",
    "\n",
    "    feature_vector = {}\n",
    "    \n",
    "    # Timbral Texture Features\n",
    "    \n",
    "    # 0 indices are due to array shape\n",
    "    feature_vector['spc_cnt'] = lrf.spectral_centroid(y=signal, sr=sr)[0][0] # Spectral Centroid\n",
    "    feature_vector['spc_roff'] = lrf.spectral_rolloff(y=signal, sr=sr)[0][0] # Rolloff\n",
    "    feature_vector['zc']  = np.array(np.sum(np.abs(np.diff(np.sign(signal)))) / (2 * len(signal)))\n",
    "        \n",
    "    for idx, mfcc in enumerate(lrf.mfcc(y=signal, n_mfcc=n_mfcc, sr=sr)): # First 5 MFCCs\n",
    "        feature_vector['mfcc_' + str(idx)] = mfcc[0]\n",
    "    \n",
    "    for idx, chroma in enumerate(lrf.chroma_stft(y=signal, n_chroma=n_chr, sr=sr)): #chromagram\n",
    "        feature_vector['chr_' + str(idx)] = chroma[0]\n",
    "\n",
    "    for idx, mel in enumerate(lr.power_to_db(lrf.melspectrogram(y=signal, sr=sr))[:n_mel, :]):\n",
    "        feature_vector['mel_' + str(idx)] = mel[0]\n",
    "    \n",
    "    # Iterate over each frequency band\n",
    "    band_powers = {}\n",
    "\n",
    "    # Calculate the power spectral density (PSD) using Welch's method\n",
    "    frequencies, psd = welch(signal, fs=sampling_frequency, nperseg=1024)\n",
    "\n",
    "    # Iterate over each frequency band\n",
    "    # iterations are reversed due to performance differences in certain models\n",
    "    # TODO: reversing process should be improved, way too clunky rn.\n",
    "    for band, (low_freq, high_freq) in reversed(frequency_bands.items()):\n",
    "        # Find indices corresponding to the specified frequency range\n",
    "        band_indices = np.where((frequencies >= low_freq) & (frequencies < high_freq))\n",
    "        # Integrate PSD within the band's frequency range to compute band power\n",
    "        band_power = np.trapz(psd[band_indices], frequencies[band_indices])\n",
    "        band_powers[band] = band_power\n",
    "        feature_vector[band + '_power'] = band_power\n",
    "    \n",
    "    for band in reversed(list(band_powers)):\n",
    "        for child_band in reversed(list(band_powers)):\n",
    "            if child_band == band:\n",
    "                continue\n",
    "            feature_vector[band + '_' + child_band] = band_powers[band]/ band_powers[child_band]\n",
    "        band_powers.pop(band)\n",
    "    \n",
    "    # Calculate the first differences\n",
    "    first_differences = np.diff(signal, n=1)\n",
    "\n",
    "    # Calculate the mean of the absolute values of the first differences\n",
    "    feature_vector['mean_abs_sec_dif'] = np.mean(np.abs(first_differences))\n",
    "\n",
    "    # TODO: explain feature\n",
    "    feature_vector['dfa'] = dfa(signal, overlap=False)\n",
    "    \n",
    "    yf = fft(signal)\n",
    "    yf = 2.0/N * np.abs(yf[0:N//2])\n",
    "    np.clip(yf, 0, 15)\n",
    "    yf = (yf - np.min(yf))/(np.max(yf) - np.min(yf))\n",
    "    peaks, _ = scipy.signal.find_peaks(yf, height=0)\n",
    "    peaks, _ = scipy.signal.find_peaks(yf, height=np.max(yf[peaks])*0.25)\n",
    "\n",
    "    xf = fftfreq(N, T)[:N//2]\n",
    "\n",
    "    # frequency of the maximum peak    \n",
    "    #feature_vector['peak_freq'] = xf[yf == np.max(yf[peaks])]\n",
    "\n",
    "    # maximum frequency of peaks\n",
    "    #feature_vector['max_freq'] = xf[peaks][len(xf[peaks]) - 1]\n",
    "    \n",
    "    # peak slope\n",
    "    res = linregress(xf[peaks], yf[peaks])\n",
    "    feature_vector['slope'] = res.slope\n",
    "    \n",
    "    feature_vector['skew'] = [skew(signal)][0] #no\n",
    "    feature_vector['kurtosis'] = [kurtosis(signal)][0] #no\n",
    "\n",
    "    activity, mobility, complexity = hjorth_parameters(signal) #no\n",
    "    feature_vector['activity'] = [activity][0]\n",
    "    feature_vector['mobility'] = [mobility][0]\n",
    "    feature_vector['complexity'] = [complexity][0]\n",
    "    feature_vector['rms'] = np.sqrt(np.mean(signal**2))\n",
    "\n",
    "    # TODO: group this with the other lrf features\n",
    "    for idx, tonal in enumerate(lrf.tonnetz(y=signal)[:n_tonnetz, :]):\n",
    "        feature_vector['ton_' + str(idx)] = tonal[0]\n",
    "        \n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'drowsiness-dataset.mat' # changed to relative path\n",
    "data_dict = scipy.io.loadmat(dataset_path)\n",
    "subjects = list(data_dict[\"subindex\"])\n",
    "states = [i[0] for i in data_dict[\"substate\"]]\n",
    "subjects = [i[0] for i in data_dict[\"subindex\"]]\n",
    "eeg = data_dict[\"EEGsample\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names =  [\"Fp1\", \"Fp2\", \"F7\", \"F3\", \"Fz\", \"F4\", \"F8\", \"FT7\", \"FC3\", \"FCZ\", \"FC4\", \"FT8\", \"T3\", \"C3\", \"Cz\", \"C4\", \"T4\", \"TP7\", \"CP3\", \"CPz\", \"CP4\", \"TP8\", \"T5\", \"P3\", \"PZ\", \"P4\", \"T6\", \"O1\", \"Oz\" , \"O2\"]\n",
    "channel_idx =  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
    "channel_names = dict(zip(channel_names, channel_idx))\n",
    "\n",
    "def select_channel(data, channel_list):\n",
    "    selection = []\n",
    "    channel_col = []\n",
    "    for i in range(len(channel_list)):\n",
    "        selection.append(data[:, channel_names[channel_list[i]], :])\n",
    "        channel_col.append([channel_list[i]] * data.shape[0])\n",
    "    selected_data = np.concatenate(selection)\n",
    "    channel_col = np.concatenate(channel_col)\n",
    "    return selected_data, channel_col\n",
    "\n",
    "channel_list = ['F3', 'F4', 'C3', 'Cz', 'Oz', 'Fp1', 'Fp2', 'FT7', 'F8', 'Fz', 'C4']\n",
    "labels = states * len(channel_list)\n",
    "subjects = subjects * len(channel_list)\n",
    "data, channel_col = select_channel(eeg, channel_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction on Selected Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1979.5855391025543\n"
     ]
    }
   ],
   "source": [
    "# extracted features np array olabilir liste yerine\n",
    "import time\n",
    "start = time.time()\n",
    "extracted_features = []\n",
    "for i in range(data.shape[0]):\n",
    "    signal_features = feature_extraction(data[i,:])\n",
    "    extracted_features.append(signal_features)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(extracted_features).fillna(0)\n",
    "df.insert(loc = 0, column = 'channels', value = channel_col)\n",
    "df['subjects'] = subjects\n",
    "df['label'] = labels\n",
    "df.to_csv(\"eeg_features.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
